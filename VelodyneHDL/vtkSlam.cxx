//=========================================================================
//
// Copyright 2018 Kitware, Inc.
// Author: Guilbert Pierre (spguilbert@gmail.com)
// Data: 03-27-2018
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//=========================================================================

// This slam algorithm is inspired by the LOAM algorithm:
// J. Zhang and S. Singh. LOAM: Lidar Odometry and Mapping in Real-time.
// Robotics: Science and Systems Conference (RSS). Berkeley, CA, July 2014.

// The algorithm is composed of three sequential steps:
//
// - Keypoints extraction: this step consists of extracting keypoints over
// the points clouds. To do that, the laser lines / scans are trated indepently.
// The laser lines are projected onto the XY plane and are rescale depending on
// their vertical angle. Then we compute their curvature and create two class of
// keypoints. The edges keypoints which correspond to points with a hight curvature
// and planar points which correspond to points with a low curvature.
//
// - Ego-Motion: this step consists of recovering the motion of the lidar
// sensor between two frames (two sweeps). The motion is modelized by a constant
// velocity and angular velocity between two frames (i.e null acceleration). 
// Hence, we can parameterize the motion by a rotation and translation per sweep / frame
// and interpolate the transformation inside a frame using the timestamp of the points.
// Since the points clouds generated by a lidar are sparses we can't design a
// pairwise match between keypoints of two successive frames. Hence, we decided to use
// a closest-point matching between the keypoints of the current frame
// and the geometrics features derived from the keypoints of the previous frame.
// The geometrics features are lines or planes and are computed using the edges keypoints
// and planar keypoints of the previous frame. Once the matching is done, a keypoint
// of the current frame is matched with a plane / line (depending of the
// nature of the keypoint) from the previous frame. Then, we recover R and T by
// minimizing the function f(R, T) = sum(d(point, line)^2) + sum(d(point, plane)^2).
// Which can be writen f(R, T) = sum((R*X+T-P).t*A*(R*X+T-P)) where:
// - X is a keypoint of the current frame
// - P is a point of the corresponding line / plane
// - A = (n*n.t) with n being the normal of the plane
// - A = (I - n*n.t).t * (I - n*n.t) with n being a director vector of the line
// Since the function f(R, T) is a non-linear mean square error function
// we decided to use the Levenberg-Marquardt algorithm to recover its argmin.
//
// - Mapping: This step consists of refining the motion recovered in the Ego-Motion
// step and to add the new frame in the environment map. Thanks to the ego-motion
// recovered at the previous step it is now possible to estimate the new position of
// the sensor in the map. We use this estimation as an initial point (R0, T0) and we
// perform an optimization again using the keypoints of the current frame and the matched
// keypoints of the map (and not only the previous frame this time!). Once the position in the
// map has been refined from the first estimation it is then possible to update the map by
// adding the keypoints of the current frame into the map.
//
// In the following programs : "vtkSlam.h" and "vtkSlam.cxx" the lidar
// coordinate system {L} is a 3D coordinate system with its origin at the
// geometric center of the lidar. The world coordinate system {W} is a 3D
// coordinate system which coinciding with {L] at the initial position. The
// points will be denoted by the ending letter L or W if they belong to
// the corresponding coordinate system

// LOCAL
#include "vtkSlam.h"
#include "vtkVelodyneHDLReader.h"
#include "vtkVelodyneTransformInterpolator.h"
#include "vtkPCLConversions.h"
// STD
#include <sstream>
#include <algorithm>
#include <cmath>
#include <cfloat>
#include <ctime>
// VTK
#include <vtkCellArray.h>
#include <vtkCellData.h>
#include <vtkDataArray.h>
#include <vtkDoubleArray.h>
#include <vtkFloatArray.h>
#include <vtkInformation.h>
#include <vtkInformationVector.h>
#include <vtkMath.h>
#include <vtkNew.h>
#include <vtkObjectFactory.h>
#include <vtkPointData.h>
#include <vtkPoints.h>
#include <vtkPolyData.h>
#include <vtkPolyLine.h>
#include <vtkSmartPointer.h>
#include <vtkStreamingDemandDrivenPipeline.h>
#include <vtkQuaternion.h>
#include <vtkUnsignedCharArray.h>
#include <vtkUnsignedShortArray.h>
#include <vtkTransform.h>
#include <vtkPoints.h>
#include <vtkTransform.h>
#include <vtkTransformPolyDataFilter.h>
// EIGEN
#include <Eigen/Dense>
// PCL
#include <pcl/point_types.h>
#include <pcl/filters/voxel_grid.h>
// BOOST
#include <boost/filesystem.hpp>
#include <boost/foreach.hpp>
#include <boost/preprocessor.hpp>
#include <boost/property_tree/ptree.hpp>
#include <boost/property_tree/xml_parser.hpp>
#include <boost/algorithm/string.hpp>
// CERES
#include <ceres/ceres.h>
#include <glog/logging.h>

vtkStandardNewMacro(vtkSlam);


namespace {
//-----------------------------------------------------------------------------
template <typename T>
Eigen::Matrix<T, 3, 3> GetRotationMatrixT(Eigen::Matrix<T, 3, 1> T)
{
  // Rotation and translation relative
  Eigen::Matrix<T, 3, 3> Rx, Ry, Rz, R;
  // rotation around X-axis
  Rx << 1,         0,          0,
        0, ceres::cos(T(0)), -ceres::sin(T(0)),
        0, ceres::sin(T(0)),  ceres::cos(T(0));
  // rotation around Y-axis
  Ry <<  ceres::cos(T(1)), 0, ceres::sin(T(1)),
        0,          1,         0,
        -ceres::sin(T(1)), 0, ceres::cos(T(1));
  // rotation around Z-axis
  Rz << ceres::cos(T(2)), -ceres::sin(T(2)), 0,
        ceres::sin(T(2)),  ceres::cos(T(2)), 0,
                0,          0, 1;

  // full rotation
  R = Rz * Ry * Rx;
  return R;
}

//-----------------------------------------------------------------------------
struct AffineIsometryResidual
{
public:
  AffineIsometryResidual(Eigen::Matrix<double, 3, 3> argA,
                         Eigen::Matrix<double, 3, 1> argC,
                         Eigen::Matrix<double, 3, 1> argX)
  {
    this->A = argA;
    this->C = argC;
    this->X = argX;
  }

  template <typename T>
  bool operator()(const T* const rx, const T* const ry, const T* const rz,
                  const T* const tx, const T* const ty, const T* const tz,
                  T* residual) const
  {
    // Convert internal double matrix
    // to a Jet matrix for auto diff calculous
    Eigen::Matrix<T, 3, 3> Ac;
    for (int i = 0; i < 3; ++i)
      for (int j = 0; j < 3; ++j)
        Ac(i, j) = T(this->A(i, j));

    // store sin / cos values for this angle
    T crx = ceres::cos(rx[0]); T srx = ceres::sin(rx[0]);
    T cry = ceres::cos(ry[0]); T sry = ceres::sin(ry[0]);
    T crz = ceres::cos(rz[0]); T srz = ceres::sin(rz[0]);

    // Compute Y = R(theta) * X + T - C
    T Yx = cry*crz*T(X(0)) + (srx*sry*crz-crx*srz)*T(X(1)) + (crx*sry*crz+srx*srz)*T(X(2)) + tx[0] - T(C(0));
    T Yy = cry*srz*T(X(0)) + (srx*sry*srz+crx*crz)*T(X(1)) + (crx*sry*srz-srx*crz)*T(X(2)) + ty[0] - T(C(1));
    T Yz = -sry*T(X(0)) + srx*cry*T(X(1)) + crx*cry*T(X(2)) + tz[0] - T(C(2));

    // Compute final residual value which is:
    // Ht * A * H with H = R(theta)X + T
    Eigen::Matrix<T, 3, 1> Y;
    Y << Yx, Yy, Yz;
    residual[0] = ceres::sqrt((Y.transpose() * Ac * Y)(0));

    return true;
  }

private:
  Eigen::Matrix<double, 3, 3> A;
  Eigen::Matrix<double, 3, 1> C;
  Eigen::Matrix<double, 3, 1> X;
};

class LineFitting
{
public:
  LineFitting();

  // Fitting using PCA
  void FitPCA(std::vector<Eigen::Matrix<double, 3, 1> >& points);

  // Poor but fast fitting using
  // extremities of the distribution
  void FitFast(std::vector<Eigen::Matrix<double, 3, 1> >& points);

  // Direction and position
  Eigen::Matrix<double, 3, 1> Direction;
  Eigen::Matrix<double, 3, 1> Position;
  Eigen::Matrix<double, 3, 3> SemiDist;
  double MaxDistance;

  Eigen::Matrix<double, 3, 3> I3;
};

//-----------------------------------------------------------------------------
LineFitting::LineFitting()
{
  this->I3 << 1, 0, 0,
              0, 1, 0,
              0, 0, 1;
}

//-----------------------------------------------------------------------------
void LineFitting::FitPCA(std::vector<Eigen::Matrix<double, 3, 1> >& points)
{
  Eigen::Matrix<double, 3, 3> I3;
  I3 << 1, 0, 0,
        0, 1, 0,
        0, 0, 1;

  // Compute PCA to determine best line approximation
  // of the points distribution
  Eigen::MatrixXd data(points.size(), 3);

  for (unsigned int k = 0; k < points.size(); k++)
  {
    data.row(k) = points[k];
  }

  Eigen::Matrix<double, 3, 1> mean = data.colwise().mean();
  Eigen::MatrixXd centered = data.rowwise() - mean.transpose();
  Eigen::MatrixXd cov = centered.transpose() * centered;
  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> eig(cov);

  // Eigen values
  Eigen::MatrixXd D(1,3);
  // Eigen vectors
  Eigen::MatrixXd V(3,3);

  D = eig.eigenvalues();
  V = eig.eigenvectors();

  // Direction
  this->Direction = V.col(2).normalized();

  // Position
  this->Position = mean;

  // Semi distance matrix
  // (polar form associated to
  // a bilineare symmetric positive
  // semi-definite matrix)
  this->SemiDist = (this->I3 - this->Direction * this->Direction.transpose());
  this->SemiDist = this->SemiDist.transpose() * this->SemiDist;
}

//-----------------------------------------------------------------------------
void LineFitting::FitFast(std::vector<Eigen::Matrix<double, 3, 1> >& points)
{
  // Take the two extrems points of the neighborhood
  // i.e the farest and the closest to the current point
  Eigen::Matrix<double, 3, 1> U = points[0];
  Eigen::Matrix<double, 3, 1> V = points[points.size() - 1];

  // direction
  this->Direction = (V - U).normalized();

  // position
  this->Position = U;

  // Semi distance matrix
  // (polar form associated to
  // a bilineare symmetric positive
  // semi-definite matrix)
  this->SemiDist = (this->I3 - this->Direction * this->Direction.transpose());
  this->SemiDist = this->SemiDist.transpose() * this->SemiDist;
}

//-----------------------------------------------------------------------------
Eigen::Matrix3d GetRotationMatrix(Eigen::Matrix<double, 6, 1> T)
{
  // T(0) = rx, T(1) = ry, T(2) = rz
  // R = Rz(rz) * Ry(ry) * Rx(rx)
  return Eigen::Matrix3d(
        Eigen::AngleAxisd(T(2), Eigen::Vector3d::UnitZ())       /* rotation around Z-axis */
        * Eigen::AngleAxisd(T(1), Eigen::Vector3d::UnitY())     /* rotation around Y-axis */
        * Eigen::AngleAxisd(T(0), Eigen::Vector3d::UnitX()));   /* rotation around X-axis */
}

//-----------------------------------------------------------------------------
template <typename T>
vtkSmartPointer<T> CreateDataArray(const char* name, vtkIdType np, vtkPolyData* pd)
{
  vtkSmartPointer<T> array = vtkSmartPointer<T>::New();
  array->Allocate(np);
  array->SetName(name);

  if (pd)
    {
    pd->GetPointData()->AddArray(array);
    }

  return array;
}

//-----------------------------------------------------------------------------
template <typename T>
std::vector<size_t> sortIdx(const std::vector<T> &v)
{
  // initialize original index locations
  std::vector<size_t> idx(v.size());
  std::iota(idx.begin(), idx.end(), 0);

  // sort indexes based on comparing values in v
  std::sort(idx.begin(), idx.end(),
       [&v](size_t i1, size_t i2) {return v[i1] > v[i2];});

  return idx;
}

//-----------------------------------------------------------------------------
std::clock_t startTime;

//-----------------------------------------------------------------------------
void InitTime()
{
  startTime = std::clock();
}

//-----------------------------------------------------------------------------
void StopTimeAndDisplay(std::string functionName)
{
  std::clock_t endTime = std::clock();
  double dt = static_cast<double>(endTime - startTime) / CLOCKS_PER_SEC;
  std::cout << "  -time elapsed in function <" << functionName << "> : " << dt << " sec" << std::endl;
}

//-----------------------------------------------------------------------------
double Rad2Deg(double val)
{
  return val / vtkMath::Pi() * 180;
}

//-----------------------------------------------------------------------------
double Deg2Rad(double val)
{
  return val / 180 * vtkMath::Pi();
}
}

// The map reconstructed from the slam algorithm is stored in a voxel grid
// which split the space in differents region. From this voxel grid it is possible
// to only load the parts of the map which are pertinents when we run the mapping
// optimization algorithm. Morevover, when a a region of the space is too far from
// the current sensor position it is possible to remove the points stored in this region
// and to move the voxel grid in a closest region of the sensor position. This is used
// to decrease the memory used by the algorithm
class RollingGrid {
public:
  RollingGrid()
  {
    // should initialize using Tworld + size / 2
    this->VoxelGridPosition[0] = 0;
    this->VoxelGridPosition[1] = 0;
    this->VoxelGridPosition[2] = 0;

    this->LeafVoxelFilterSize = 0.2;
  }

  RollingGrid(double posX, double posY, double posZ)
  {
    // should initialize using Tworld + size / 2
    this->VoxelGridPosition[0] = static_cast<int>(posX);
    this->VoxelGridPosition[1] = static_cast<int>(posY);
    this->VoxelGridPosition[2] = static_cast<int>(posZ);;

    this->LeafVoxelFilterSize = 0.2;
  }

  // roll the grid to enable adding new point cloud
  void Roll(Eigen::Matrix<double, 6, 1> &T)
  {
    // Very basic implementation where the grid is not circular

    // compute the position of the new frame center in the grid
    int frameCenterX = std::floor(T[3] / this->VoxelSize) - this->VoxelGridPosition[0];
    int frameCenterY = std::floor(T[4] / this->VoxelSize) - this->VoxelGridPosition[1];
    int frameCenterZ = std::floor(T[5] / this->VoxelSize) - this->VoxelGridPosition[2];

    // shift the voxel grid to the left
    while (frameCenterX - std::ceil(this->PointCloud_NbVoxelX / 2) <= 0)
    {
      for (int j = 0; j < this->Grid_NbVoxelY; j++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          for (int i = this->Grid_NbVoxelX - 1; i > 0; i--)
          {
            this->grid[i][j][k] = this->grid[i-1][j][k];
          }
          this->grid[0][j][k].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterX++;
      this->VoxelGridPosition[0]--;
    }

    // shift the voxel grid to the right
    while (frameCenterX + std::ceil(this->PointCloud_NbVoxelX / 2) >= this->Grid_NbVoxelX - 1)
    {
      for (int j = 0; j < this->Grid_NbVoxelY; j++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          for (int i = 0; i < this->Grid_NbVoxelX - 1; i++)
          {
            this->grid[i][j][k] = this->grid[i+1][j][k];
          }
          this->grid[Grid_NbVoxelX-1][j][k].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterX--;
      this->VoxelGridPosition[0]++;
    }

    // shift the voxel grid to the bottom
    while (frameCenterY - std::ceil(this->PointCloud_NbVoxelY / 2) <= 0)
    {
      for (int i = 0; i < this->Grid_NbVoxelX; i++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          for (int j = this->Grid_NbVoxelY - 1; j > 0; j--)
          {
            this->grid[i][j][k] = this->grid[i][j-1][k];
          }
          this->grid[i][0][k].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterY++;
      this->VoxelGridPosition[1]--;
//      cout << "bottom";
    }

    // shift the voxel grid to the top
    while (frameCenterY + std::ceil(this->PointCloud_NbVoxelY / 2) >= this->Grid_NbVoxelY - 1)
    {
      for (int i = 0; i < this->Grid_NbVoxelX; i++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          for (int j = 0; j < this->Grid_NbVoxelY - 1; j++)
          {
            this->grid[i][j][k] = this->grid[i][j+1][k];
          }
          this->grid[i][Grid_NbVoxelY-1][k].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterY--;
      this->VoxelGridPosition[1]++;
    }

    // shift the voxel grid to the "camera"
    while (frameCenterZ - std::ceil(this->PointCloud_NbVoxelZ / 2) <= 0)
    {
      for (int i = 0; i < this->Grid_NbVoxelX; i++)
      {
        for (int j = 0; j < this->Grid_NbVoxelY; j++)
        {
          for (int k = this->Grid_NbVoxelZ - 1; k > 0; k--)
          {
            this->grid[i][j][k] = this->grid[i][j][k-1];
          }
          this->grid[i][j][0].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterZ++;
      this->VoxelGridPosition[2]--;
    }

    // shift the voxel grid to the "horizon"
    while (frameCenterZ + std::ceil(this->PointCloud_NbVoxelZ  / 2) >= this->Grid_NbVoxelZ - 1)
    {
      for (int i = 0; i < this->Grid_NbVoxelX; i++)
      {
        for (int j = 0; j < this->Grid_NbVoxelY; j++)
        {
          for (int k = 0; k < this->Grid_NbVoxelZ - 1; k++)
          {
            this->grid[i][j][k] = this->grid[i][j][k+1];
          }
          this->grid[i][j][Grid_NbVoxelZ-1].reset(new pcl::PointCloud<Point>());
        }
      }
      frameCenterZ--;
      this->VoxelGridPosition[2]++;
    }
  }

  // get points arround T
  pcl::PointCloud<Point>::Ptr Get(Eigen::Matrix<double, 6, 1> &T)
  {
    // compute the position of the new frame center in the grid
    int frameCenterX = std::floor(T[3] / this->VoxelSize) - this->VoxelGridPosition[0];
    int frameCenterY = std::floor(T[4] / this->VoxelSize) - this->VoxelGridPosition[1];
    int frameCenterZ = std::floor(T[5] / this->VoxelSize) - this->VoxelGridPosition[2];

    pcl::PointCloud<Point>::Ptr intersection(new pcl::PointCloud<Point>);

    // Get all voxel in intersection should use ceil here
    for (int i = frameCenterX - std::ceil(this->PointCloud_NbVoxelX / 2); i <= frameCenterX + std::ceil(this->PointCloud_NbVoxelX / 2); i++)
    {
      for (int j = frameCenterY - std::ceil(this->PointCloud_NbVoxelY / 2); j <= frameCenterY + std::ceil(this->PointCloud_NbVoxelY / 2); j++)
      {
        for (int k = frameCenterZ - std::ceil(this->PointCloud_NbVoxelZ / 2); k <= frameCenterZ + std::ceil(this->PointCloud_NbVoxelZ / 2); k++)
        {
          if (i < 0 || i > (this->Grid_NbVoxelX - 1) ||
              j < 0 || j > (this->Grid_NbVoxelY - 1) ||
              k < 0 || k > (this->Grid_NbVoxelZ - 1))
          {
            continue;
          }
          pcl::PointCloud<Point>:: Ptr voxel = this->grid[i][j][k];
          for (int l = 0; l < voxel->size(); l++)
          {
            intersection->push_back(voxel->at(l));
          }
        }
      }
    }
    return intersection;
  }

  // get all points
  pcl::PointCloud<Point>::Ptr Get()
  {
    pcl::PointCloud<Point>::Ptr intersection(new pcl::PointCloud<Point>);

    // Get all voxel in intersection should use ceil here
    for (unsigned int i = 0; i < Grid_NbVoxelX; i++)
    {
      for (unsigned int j = 0; j < Grid_NbVoxelY; j++)
      {
        for (unsigned int k = 0; k < Grid_NbVoxelZ; k++)
        {
          pcl::PointCloud<Point>:: Ptr voxel = this->grid[i][j][k];
          for (int l = 0; l < voxel->size(); l++)
          {
            intersection->push_back(voxel->at(l));
          }
        }
      }
    }
    return intersection;
  }

  // add some points to the grid
  void Add(pcl::PointCloud<Point>::Ptr pointcloud)
  {
    if (pointcloud->size() == 0)
    {
      vtkGenericWarningMacro("Pointcloud empty, voxel grid not updated");
      return;
    }
    this->vizualisation.clear();

    // Voxel to filte because new points were add
    std::vector<std::vector<std::vector<int> > > voxelToFilter(Grid_NbVoxelX, std::vector<std::vector<int> >(Grid_NbVoxelY, std::vector<int>(Grid_NbVoxelZ, 0)));

    // Add points in the rolling grid
    int outlier = 0; // point who are not in the rolling grid
    for (int i = 0; i < pointcloud->size(); i++)
    {
      Point pts = pointcloud->points[i];
      // find the closest coordinate
      int cubeIdxX = std::floor(pts.x / this->VoxelSize) - this->VoxelGridPosition[0];
      int cubeIdxY = std::floor(pts.y / this->VoxelSize) - this->VoxelGridPosition[1];
      int cubeIdxZ = std::floor(pts.z / this->VoxelSize) - this->VoxelGridPosition[2];


      if (cubeIdxX >= 0 && cubeIdxX < this->Grid_NbVoxelX &&
        cubeIdxY >= 0 && cubeIdxY < this->Grid_NbVoxelY &&
        cubeIdxZ >= 0 && cubeIdxZ < this->Grid_NbVoxelZ)
      {
        voxelToFilter[cubeIdxX][cubeIdxY][cubeIdxZ] = 1;
        grid[cubeIdxX][cubeIdxY][cubeIdxZ]->push_back(pts);
        // for vizualization purpose only
        this->vizualisation.push_back(cubeIdxX);
      }
      else
      {
        this->vizualisation.push_back(-1);
        outlier++;
      }
    }

    // Filter the modified pointCloud
    pcl::VoxelGrid<Point> downSizeFilter;
    downSizeFilter.setLeafSize(LeafVoxelFilterSize, LeafVoxelFilterSize, LeafVoxelFilterSize); // one point per 20x20x20 cm
    for (int i = 0; i < this->Grid_NbVoxelX; i++)
    {
      for (int j = 0; j < this->Grid_NbVoxelY; j++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          if (voxelToFilter[i][j][k] == 1)
          {
            pcl::PointCloud<Point>::Ptr tmp(new pcl::PointCloud<Point>());
            downSizeFilter.setInputCloud(grid[i][j][k]);
            downSizeFilter.filter(*tmp);
            grid[i][j][k] = tmp;
          }
        }
      }
    }
  }

  // return size
  int NumberOfPoints()
  {
    int size = 0;
    for (int i = 0; i < this->Grid_NbVoxelX; i++)
    {
      for (int j = 0; j < this->Grid_NbVoxelY; j++)
      {
        for (int k = 0; k < this->Grid_NbVoxelZ; k++)
        {
          size += this->grid[i][j][k]->size();
        }
      }
    }
    return size;
  }

  const unsigned int Get_VoxelSize() const
  {
    return this->VoxelSize;
  }

  void Set_VoxelSize(const unsigned int size)
  {
    this->VoxelSize = size;
  }

  void Get_Grid_NbVoxel(double nbVoxel[3]) const
  {
    nbVoxel[0] = this->Grid_NbVoxelX;
    nbVoxel[1] = this->Grid_NbVoxelY;
    nbVoxel[2] = this->Grid_NbVoxelZ;
  }

  void Set_Grid_NbVoxel(const double nbVoxel[3])
  {
    this->Grid_NbVoxelX = nbVoxel[0];
    this->Grid_NbVoxelY = nbVoxel[1];
    this->Grid_NbVoxelZ = nbVoxel[2];
    grid.resize(Grid_NbVoxelX);
    for (int i = 0; i < Grid_NbVoxelX; i++)
    {
      grid[i].resize(Grid_NbVoxelY);
      for (int j = 0; j < Grid_NbVoxelY; j++)
      {
        grid[i][j].resize(Grid_NbVoxelZ);
        for (int k = 0; k < Grid_NbVoxelZ; k++)
        {
          grid[i][j][k].reset(new pcl::PointCloud<Point>());
        }
      }
    }
  }

  void Get_PointCloud_NbVoxel(double nbVoxel[3]) const
  {
    nbVoxel[0] = this->PointCloud_NbVoxelX;
    nbVoxel[1] = this->PointCloud_NbVoxelY;
    nbVoxel[2] = this->PointCloud_NbVoxelZ;
  }
  void Set_PointCloud_NbVoxel(const double nbVoxel[3])
  {
    this->PointCloud_NbVoxelX = nbVoxel[0];
    this->PointCloud_NbVoxelY = nbVoxel[1];
    this->PointCloud_NbVoxelZ = nbVoxel[2];
  }

  const double Get_LeafVoxelFilterSize() const
  {
    return this->LeafVoxelFilterSize;
  }

  void Set_LeafVoxelFilterSize(const double size)
  {
    this->LeafVoxelFilterSize = size;
  }

private:
  // width of a voxel in m
  // since the voxels are cubic
  // their volume is VoxelSize^3
  unsigned int VoxelSize;

  // number of voxel / axis
  unsigned int Grid_NbVoxelX;
  unsigned int Grid_NbVoxelY;
  unsigned int Grid_NbVoxelZ;

  // Size of a pointcloud in voxel
  unsigned int PointCloud_NbVoxelX;
  unsigned int PointCloud_NbVoxelY;
  unsigned int PointCloud_NbVoxelZ;

  double LeafVoxelFilterSize;

  // grid of pointcloud
  std::vector<std::vector<std::vector<pcl::PointCloud<Point>::Ptr> > > grid;

  // Position of the VoxelGrid
  int VoxelGridPosition[3];

  // vizualisation
  std::vector<int> vizualisation;
};

//-----------------------------------------------------------------------------
int vtkSlam::RequestData(vtkInformation *vtkNotUsed(request),
vtkInformationVector **inputVector, vtkInformationVector *outputVector)
{
  // get info
  vtkInformation *outInfo0 = outputVector->GetInformationObject(0);
  vtkInformation *outInfo1 = outputVector->GetInformationObject(1);
  vtkInformation *outInfo2 = outputVector->GetInformationObject(2);
  vtkInformation *outInfo3 = outputVector->GetInformationObject(3);
  vtkInformation *outInfo4 = outputVector->GetInformationObject(4);
  vtkInformation *outInfo5 = outputVector->GetInformationObject(5);

  // get output
  vtkPolyData *output0 = vtkPolyData::SafeDownCast(
    outInfo0->Get(vtkDataObject::DATA_OBJECT()));
  vtkPolyData *output1 = vtkPolyData::SafeDownCast(
    outInfo1->Get(vtkDataObject::DATA_OBJECT()));
  vtkPolyData *output2 = vtkPolyData::SafeDownCast(
    outInfo2->Get(vtkDataObject::DATA_OBJECT()));
  vtkPolyData *output3 = vtkPolyData::SafeDownCast(
    outInfo3->Get(vtkDataObject::DATA_OBJECT()));
  vtkPolyData *output4 = vtkPolyData::SafeDownCast(
    outInfo4->Get(vtkDataObject::DATA_OBJECT()));
  vtkPolyData *output5 = vtkPolyData::SafeDownCast(
    outInfo5->Get(vtkDataObject::DATA_OBJECT()));

  // output 0 - Current Frame
  // add all debug information if displayMode == True
  if (DisplayMode = true && this->NbrFrameProcessed > 0)
  {
    this->DisplayLaserIdMapping(this->vtkCurrentFrame);
    this->DisplayRelAdv(this->vtkCurrentFrame);
    AddVectorToPolydataPoints<double, vtkDoubleArray>(this->Angles, "angles_line", this->vtkCurrentFrame);
    AddVectorToPolydataPoints<double, vtkDoubleArray>(this->DepthGap, "depth_gap", this->vtkCurrentFrame);
    AddVectorToPolydataPoints<double, vtkDoubleArray>(this->BlobScore, "blob_score", this->vtkCurrentFrame);
    AddVectorToPolydataPoints<int, vtkIntArray>(this->IsPointValid, "is_point_valid", this->vtkCurrentFrame);
    AddVectorToPolydataPoints<int, vtkIntArray>(this->Label, "keypoint_label", this->vtkCurrentFrame);
  }
  // get transform
  vtkSmartPointer<vtkTransform> transform = vtkSmartPointer<vtkTransform>::New();
  transform->Translate(Tworld[3], Tworld[4], Tworld[5]);
  transform->RotateX(Rad2Deg(Tworld[0]));
  transform->RotateY(Rad2Deg(Tworld[1]));
  transform->RotateZ(Rad2Deg(Tworld[2]));
  // create transform filter and transformt the current frame
  vtkSmartPointer<vtkTransformPolyDataFilter> transformFilter = vtkSmartPointer<vtkTransformPolyDataFilter>::New();
  transformFilter->SetInputData(this->vtkCurrentFrame);
  transformFilter->SetTransform(transform);
  transformFilter->Update();
  output0->ShallowCopy(transformFilter->GetOutput());

  // output 1 - Trajectory
  // create polyLine
  vtkSmartPointer<vtkPolyLine> polyLine = vtkSmartPointer<vtkPolyLine>::New();
  int NbPosition = Trajectory->GetNumberOfPoints();
  polyLine->GetPointIds()->SetNumberOfIds(NbPosition);
  for(unsigned int i = 0; i < NbPosition; i++)
  {
    polyLine->GetPointIds()->SetId(i,i);
  }
  // create cells for Trajectory
  vtkSmartPointer<vtkCellArray> cells = vtkSmartPointer<vtkCellArray>::New();
  cells->InsertNextCell(polyLine);
  Trajectory->SetLines(cells);
  output1->ShallowCopy(this->Trajectory);

  // output 2 - Edges Map
  vtkSmartPointer<vtkPolyData> EdgeMap = vtkPCLConversions::PolyDataFromPointCloud(this->EdgesPointsLocalMap->Get());
  output2->ShallowCopy(EdgeMap);

  // output 3 - Planar Points Map
  vtkSmartPointer<vtkPolyData> PlanarMap = vtkPCLConversions::PolyDataFromPointCloud(this->PlanarPointsLocalMap->Get());
  output3->ShallowCopy(PlanarMap);

  // output 4 - Planar Points Map
  vtkSmartPointer<vtkPolyData> BlobMap = vtkPCLConversions::PolyDataFromPointCloud(this->BlobsPointsLocalMap->Get());
  output4->ShallowCopy(BlobMap);

  // output 5 - Orientation
  // create polyLine
  vtkSmartPointer<vtkPolyLine> polyLine2 = vtkSmartPointer<vtkPolyLine>::New();
  int NbPosition2 = Orientation->GetNumberOfPoints();
  polyLine2->GetPointIds()->SetNumberOfIds(NbPosition2);
  for(unsigned int i = 0; i < NbPosition2; i++)
  {
    polyLine2->GetPointIds()->SetId(i,i);
  }
  // create cells for Trajectory
  vtkSmartPointer<vtkCellArray> cells2 = vtkSmartPointer<vtkCellArray>::New();
  cells2->InsertNextCell(polyLine2);
  Orientation->SetLines(cells2);
  output5->ShallowCopy(this->Orientation);

  return 1;
}

int vtkSlam::RequestDataObject(vtkInformation*,
  vtkInformationVector** inputVector ,
  vtkInformationVector* outputVector)
{

  // output 0 - Current Frame
  vtkInformation* outInfo0 = outputVector->GetInformationObject(0);
  vtkPolyData* output0 = vtkPolyData::SafeDownCast(
                                          outInfo0->Get( vtkDataObject::DATA_OBJECT() ) );
  if ( ! output0 )
  {
    output0 = vtkPolyData::New();
    outInfo0->Set( vtkDataObject::DATA_OBJECT(), output0 );
    output0->FastDelete();
    this->GetOutputPortInformation(0)->Set(
                                    vtkDataObject::DATA_EXTENT_TYPE(), output0->GetExtentType() );
  }

  // output 1 - Trajectory
  vtkInformation* outInfo1 = outputVector->GetInformationObject(1);
  vtkPolyData* output1 = vtkPolyData::SafeDownCast(
                                              outInfo1->Get( vtkDataObject::DATA_OBJECT() ) );
  if ( ! output1 )
  {
    output1 = vtkPolyData::New();
    outInfo1->Set( vtkDataObject::DATA_OBJECT(), output1 );
    output1->FastDelete();
    this->GetOutputPortInformation(1)->Set(
                                    vtkDataObject::DATA_EXTENT_TYPE(), output1->GetExtentType() );
  }

  // output 2 - Edges Map
  vtkInformation* outInfo2 = outputVector->GetInformationObject(2);
  vtkPolyData* output2 = vtkPolyData::SafeDownCast(
                                              outInfo2->Get( vtkDataObject::DATA_OBJECT() ) );
  if ( ! output2 )
  {
    output2 = vtkPolyData::New();
    outInfo2->Set( vtkDataObject::DATA_OBJECT(), output2 );
    output2->FastDelete();
    this->GetOutputPortInformation(1)->Set(
                                    vtkDataObject::DATA_EXTENT_TYPE(), output2->GetExtentType() );
  }

  // output 3 - Planar Points Map
  vtkInformation* outInfo3 = outputVector->GetInformationObject(3);
  vtkPolyData* output3 = vtkPolyData::SafeDownCast(
                                              outInfo3->Get( vtkDataObject::DATA_OBJECT() ) );
  if ( ! output3 )
  {
    output3 = vtkPolyData::New();
    outInfo3->Set( vtkDataObject::DATA_OBJECT(), output3 );
    output3->FastDelete();
    this->GetOutputPortInformation(1)->Set(
                                    vtkDataObject::DATA_EXTENT_TYPE(), output3->GetExtentType() );
  }
  return 1;
}

//----------------------------------------------------------------------------
int vtkSlam::RequestUpdateExtent(
    vtkInformation* vtkNotUsed(request),
    vtkInformationVector** inputVector,
    vtkInformationVector* vtkNotUsed(outputVector))
{
  int numInputPorts = this->GetNumberOfInputPorts();
  for (int i=0; i<numInputPorts; i++)
  {
    int numInputConnections = this->GetNumberOfInputConnections(i);
    for (int j=0; j<numInputConnections; j++)
    {
      vtkInformation* inputInfo = inputVector[i]->GetInformationObject(j);
      inputInfo->Set(vtkStreamingDemandDrivenPipeline::EXACT_EXTENT(), 1);
    }
  }
  return 1;
}

//-----------------------------------------------------------------------------
int vtkSlam::RequestInformation(vtkInformation *request,
                                     vtkInformationVector **inputVector,
                                     vtkInformationVector *outputVector)
{
  return this->Superclass::RequestInformation(request, inputVector, outputVector);
}

//-----------------------------------------------------------------------------
void vtkSlam::PrintSelf(ostream& os, vtkIndent indent)
{
  this->Superclass::PrintSelf(os, indent);
}

//-----------------------------------------------------------------------------
vtkSlam::vtkSlam()
{
  this->SetNumberOfInputPorts(0);
  this->SetNumberOfOutputPorts(6);
  this->ResetAlgorithm();
}

//-----------------------------------------------------------------------------
vtkSlam::~vtkSlam()
{
  delete this->EdgesPointsLocalMap;
  delete this->PlanarPointsLocalMap;
  delete this->BlobsPointsLocalMap;
}

//-----------------------------------------------------------------------------
void vtkSlam::GetWorldTransform(double* Tworld)
{
  // Rotation and translation relative
  Eigen::Matrix<double, 3, 3> Rw;

  // full rotation
  Rw = GetRotationMatrix(this->Tworld);

  double rx = std::atan2(Rw(2, 1), Rw(2, 2));
  double ry = -std::asin(Rw(2, 0));
  double rz = std::atan2(Rw(1, 0), Rw(0, 0));
//  std::vector<double> res(6, 0);
  
  Tworld[0] = rx;
  Tworld[1] = ry;
  Tworld[2] = rz;
  Tworld[3] = this->Tworld(3);
  Tworld[4] = this->Tworld(4);
  Tworld[5] = this->Tworld(5);

//  return res;
}

//-----------------------------------------------------------------------------
void vtkSlam::PrintParameters()
{
  std::cout << "Launching slam with parameters: " << std::endl;
  std::cout << "EgoMotionLMMaxIter: " << this->EgoMotionLMMaxIter << std::endl;
  std::cout << "MappingLMMaxIter: " << this->MappingLMMaxIter << std::endl;
  std::cout << "MappingICPMaxIter: " << this->MappingICPMaxIter << std::endl;
  std::cout << "EgoMotionICPMaxIter: " << this->EgoMotionICPMaxIter << std::endl;
  std::cout << "MaxEdgePerScanLine: " << this->MaxEdgePerScanLine << std::endl;
  std::cout << "MaxPlanarsPerScanLine: " << this->MaxPlanarsPerScanLine << std::endl;
  std::cout << "EdgeSinAngleThreshold: " << this->EdgeSinAngleThreshold << std::endl;
  std::cout << "PlaneSinAngleThreshold: " << this->PlaneSinAngleThreshold << std::endl;
  std::cout << "EdgeDepthGapThreshold: " << this->EdgeDepthGapThreshold << std::endl;
  std::cout << "Lambda0: " << this->Lambda0 << std::endl;
  std::cout << "LambdaRatio: " << this->LambdaRatio << std::endl;
  std::cout << "EgoMotionLineDistanceNbrNeighbors: " << this->EgoMotionLineDistanceNbrNeighbors << std::endl;
  std::cout << "EgoMotionLineDistancefactor: " << this->EgoMotionLineDistancefactor << std::endl;
  std::cout << "MappingMaxLineDistance: " << this->MappingMaxLineDistance << std::endl;
  std::cout << "MappingPlaneDistanceNbrNeighbors: " << this->MappingPlaneDistanceNbrNeighbors << std::endl;
  std::cout << "MappingPlaneDistancefactor1: " << this->MappingPlaneDistancefactor1 << std::endl;
  std::cout << "MappingPlaneDistancefactor2: " << this->MappingPlaneDistancefactor2 << std::endl;
  std::cout << "MappingMaxPlaneDistance: " << this->MappingMaxPlaneDistance << std::endl;
  std::cout << "MaxDistanceForICPMatching: " << this->MaxDistanceForICPMatching << std::endl;
  std::cout << "AngleResolution: " << this->AngleResolution << std::endl;
  std::cout << "EgoMotionMinimumLineNeighborRejection: " << this->EgoMotionMinimumLineNeighborRejection << std::endl;
  std::cout << "MappingMinimumLineNeighborRejection: " << this->MappingMinimumLineNeighborRejection << std::endl;
  std::cout << "MappingLineMaxDistInlier: " << this->MappingLineMaxDistInlier << std::endl;
  std::cout << "Motion Model: " << this->MotionModel << std::endl;
}

//-----------------------------------------------------------------------------
void vtkSlam::ResetAlgorithm()
{
  google::InitGoogleLogging("Slam_optimisation");
  this->DisplayMode = true; // switch to false to improve speed
  this->NeighborWidth = 3;
  this->EgoMotionICPMaxIter = 5;
  this->MappingICPMaxIter = 5;
  this->EgoMotionLMMaxIter = 15;
  this->MappingLMMaxIter = 15;
  this->MinDistanceToSensor = 3.0;
  this->MaxEdgePerScanLine = 200;
  this->MaxPlanarsPerScanLine = 200;
  this->EdgeSinAngleThreshold = 0.85; // 85 degrees
  this->PlaneSinAngleThreshold = 0.5; // 50 degrees
  this->EdgeDepthGapThreshold = 0.02; // meters
  this->Undistortion = false; // should not undistord frame by default

  // Use dense planars point cloud for mapping
  this->FastSlam = true;
  this->MotionModel = 1;
  this->Lambda0 = 0.1;
  this->LambdaRatio = 1.5;
  this->KalmanEstimator.ResetKalmanFilter();

  // EgoMotion
  // edges
  this->EgoMotionLineDistanceNbrNeighbors = 5;
  this->EgoMotionMinimumLineNeighborRejection = 2;
  this->EgoMotionLineDistancefactor = 5.0;
  this->EgoMotionMaxLineDistance = 0.10; // 10 cm

  // planes
  this->EgoMotionPlaneDistanceNbrNeighbors = 5;
  this->EgoMotionPlaneDistancefactor1 = 50.0;
  this->EgoMotionPlaneDistancefactor2 = 5.0;
  this->EgoMotionMaxPlaneDistance = 0.04; // 4 cm

  // Mapping
  // edges
  this->MappingLineDistanceNbrNeighbors = 15;
  this->MappingMinimumLineNeighborRejection = 5;
  this->MappingLineMaxDistInlier = 0.3; // 30 cm
  this->MappingLineDistancefactor = 5.0;
  this->MappingMaxLineDistance = 0.2; // 20 cm

  // planes
  this->MappingPlaneDistanceNbrNeighbors = 5;
  this->MappingPlaneDistancefactor1 = 50.0;
  this->MappingPlaneDistancefactor2 = 5.0;
  this->MappingMaxPlaneDistance = 0.04; // 4 cm

  // Blobs
  this->SphericityThreshold = 0.35;
  this->IncertitudeCoef = 3.0;
  this->UseBlob = false;

  this->MaxDistanceForICPMatching = 20.0; // 20 meters

  this->NbrFrameProcessed = 0;
  this->EgoMotionIterMade = 0;
  this->MappingIterMade = 0;
  this->MappingIterMade = 0;
  this->NLasers = 0;
  this->AngleResolution = Deg2Rad(0.4);  // azimutal resolution of the VLP-16. We add an extra 20 %
  this->LaserIdMapping.clear();
  this->LaserIdMapping.resize(0);
  this->FromVTKtoPCLMapping.clear();
  this->FromVTKtoPCLMapping.resize(0);
  this->FromPCLtoVTKMapping.clear();
  this->FromPCLtoVTKMapping.resize(this->NLasers);
  this->Angles.clear();
  this->Angles.resize(this->NLasers);
  this->DepthGap.clear();
  this->DepthGap.resize(this->NLasers);
  this->BlobScore.clear();
  this->BlobScore.resize(this->NLasers);
  this->IsPointValid.clear();
  this->IsPointValid.resize(this->NLasers);
  this->Label.clear();
  this->Label.resize(this->NLasers);
  this->Tworld << 0, 0, 0, 0, 0, 0;
  this->PreviousTworld = this->Tworld;
  this->TworldList.clear();
  this->TworldList.resize(0);

  this->I3 = Eigen::Matrix3d::Identity();
  this->I6 = Eigen::Matrix<double, 6, 6>::Identity();

  EdgesPointsLocalMap = new RollingGrid();
  PlanarPointsLocalMap = new RollingGrid();
  BlobsPointsLocalMap = new RollingGrid();

  EdgesPointsLocalMap->Set_VoxelSize(10);
  PlanarPointsLocalMap->Set_VoxelSize(10);
  BlobsPointsLocalMap->Set_VoxelSize(10);

  double nbVoxel[3] = {50, 50, 50};
  EdgesPointsLocalMap->Set_Grid_NbVoxel(nbVoxel);
  PlanarPointsLocalMap->Set_Grid_NbVoxel(nbVoxel);
  BlobsPointsLocalMap->Set_Grid_NbVoxel(nbVoxel);

  nbVoxel[0] = nbVoxel[1] = nbVoxel[2] = 16;
  EdgesPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);
  PlanarPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);
  BlobsPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);

  this->Set_RollingGrid_LeafVoxelFilterSize(0.4);

  // Represent the distance that the lidar has made during one sweep
  // if it is moving at a speed of 90 km/h and spinning at a rpm
  // of 600 rotation per minute
  this->MaxDistBetweenTwoFrames = (90.0 / 3.6) * (60.0 / 600.0);

  // output of the vtk filter
  this->Trajectory = vtkSmartPointer<vtkPolyData>::New();
  this->Orientation = vtkSmartPointer<vtkPolyData>::New();

  // add the required array in the trajectory
  vtkNew<vtkPoints> points;
  CreateDataArray<vtkDoubleArray>("time", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("roll", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("pitch", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("yaw", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("Mapping: intiale cost function", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("Mapping: final cost function", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("Variance Error", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("Mapping: edges used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("Mapping: planes used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("Mapping: blobs used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("Mapping: total keypoints used", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("EgoMotion: intiale cost function", 0, this->Trajectory);
  CreateDataArray<vtkDoubleArray>("EgoMotion: final cost function", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("EgoMotion: edges used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("EgoMotion: planes used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("EgoMotion: blobs used", 0, this->Trajectory);
  CreateDataArray<vtkIntArray>("EgoMotion: total keypoints used", 0, this->Trajectory);
  this->Trajectory->SetPoints(points.GetPointer());

  // add the required array in the orientation
  vtkNew<vtkPoints> points2;
  CreateDataArray<vtkDoubleArray>("time", 0, this->Orientation);
  CreateDataArray<vtkDoubleArray>("X", 0, this->Orientation);
  CreateDataArray<vtkDoubleArray>("Y", 0, this->Orientation);
  CreateDataArray<vtkDoubleArray>("Z", 0, this->Orientation);
  this->Orientation->SetPoints(points2.GetPointer());

  this->InternalInterp = vtkSmartPointer<vtkVelodyneTransformInterpolator>::New();
  this->InternalInterp->SetInterpolationTypeToNearestLowBounded();
}

//-----------------------------------------------------------------------------
void vtkSlam::PrepareDataForNextFrame()
{
  // Reset the pcl format pointcloud to store the new frame
  this->pclCurrentFrame.reset(new pcl::PointCloud<Point>());
  for (unsigned int k = 0; k < this->NLasers; ++k)
  {
    this->pclCurrentFrameByScan[k].reset(new pcl::PointCloud<Point>());
  }

  this->CurrentEdgesPoints.reset(new pcl::PointCloud<Point>());
  this->CurrentPlanarsPoints.reset(new pcl::PointCloud<Point>());
  this->CurrentBlobsPoints.reset(new pcl::PointCloud<Point>());

  // reset vtk <-> pcl id mapping
  this->FromVTKtoPCLMapping.clear();
  this->FromVTKtoPCLMapping.resize(0);
  this->FromPCLtoVTKMapping.clear();
  this->FromPCLtoVTKMapping.resize(this->NLasers);
  this->Angles.clear();
  this->Angles.resize(this->NLasers);
  this->DepthGap.clear();
  this->DepthGap.resize(this->NLasers);
  this->BlobScore.clear();
  this->BlobScore.resize(this->NLasers);
  this->IsPointValid.clear();
  this->IsPointValid.resize(this->NLasers);
  this->Label.clear();
  this->Label.resize(this->NLasers);

  this->EgoMotionIterMade = 0;
  this->MappingIterMade = 0;
}

//-----------------------------------------------------------------------------
void vtkSlam::SetSensorCalibration(int* mapping, int nbLaser)
{
  this->NLasers = nbLaser;
  this->LaserIdMapping.resize(this->NLasers);
  for (int i = 0; i < this->NLasers; ++i)
  {
    int indice = static_cast<int>(mapping[2 * i + 1]);
    this->LaserIdMapping[indice] = i;
  }
  this->pclCurrentFrameByScan.resize(this->NLasers);

  std::cout << "mapping is : " << std::endl;
  for (unsigned int k = 0; k < this->NLasers; ++k)
  {
    std::cout << k << " <--> " << this->LaserIdMapping[k] << std::endl;
  }
}

//-----------------------------------------------------------------------------
bool vtkSlam::GetIsSensorCalibrationProvided()
{
  return (this->NLasers > 0) && (this->LaserIdMapping.size() == this->NLasers);
}

//-----------------------------------------------------------------------------
template <typename T, typename Tvtk>
void vtkSlam::AddVectorToPolydataPoints(const std::vector<std::vector<T>>& vec, const char* name, vtkPolyData* pd)
{
  vtkSmartPointer<Tvtk> array = vtkSmartPointer<Tvtk>::New();
  array->Allocate(pd->GetNumberOfPoints());
  array->SetName(name);
  for (unsigned int k = 0; k < pd->GetNumberOfPoints(); ++k)
  {
    unsigned int scan = this->FromVTKtoPCLMapping[k].first;
    unsigned int index = this->FromVTKtoPCLMapping[k].second;
    array->InsertNextTuple1(vec[scan][index]);
  }
  pd->GetPointData()->AddArray(array);
}

//-----------------------------------------------------------------------------
void vtkSlam::DisplayLaserIdMapping(vtkSmartPointer<vtkPolyData> input)
{
  vtkDataArray* idsArray = input->GetPointData()->GetArray("laser_id");
  vtkSmartPointer<vtkIntArray> laserMappingArray = vtkSmartPointer<vtkIntArray>::New();
  laserMappingArray->Allocate(input->GetNumberOfPoints());
  laserMappingArray->SetName("laser_mapping");
  for (unsigned int k = 0; k < input->GetNumberOfPoints(); ++k)
  {
    int id = static_cast<int>(idsArray->GetTuple1(k));
    id = this->LaserIdMapping[id];
    laserMappingArray->InsertNextTuple1(id);
  }
  input->GetPointData()->AddArray(laserMappingArray);
}

//-----------------------------------------------------------------------------
void vtkSlam::DisplayRelAdv(vtkSmartPointer<vtkPolyData> input)
{
  vtkSmartPointer<vtkDoubleArray> relAdvArray = vtkSmartPointer<vtkDoubleArray>::New();
  relAdvArray->Allocate(input->GetNumberOfPoints());
  relAdvArray->SetName("relative_adv");
  for (unsigned int k = 0; k < input->GetNumberOfPoints(); ++k)
  {
    unsigned int scan = this->FromVTKtoPCLMapping[k].first;
    unsigned int index = this->FromVTKtoPCLMapping[k].second;
    relAdvArray->InsertNextTuple1(this->pclCurrentFrameByScan[scan]->points[index].intensity);
  }
  input->GetPointData()->AddArray(relAdvArray);
}

//-----------------------------------------------------------------------------
void vtkSlam::AddTransform(double time)
{
  double tw[6];
  this->GetWorldTransform(tw);
  this->AddTransform(tw[0] * 180.0 / vtkMath::Pi(), tw[1] * 180.0 / vtkMath::Pi(),
                     tw[2] * 180.0 / vtkMath::Pi(), tw[3], tw[4], tw[5], time);
}

//-----------------------------------------------------------------------------
void vtkSlam::AddTransform(double rx, double ry, double rz, double tx, double ty, double tz, double t)
{
  // All the result obtained was with ZXY but it should be ZYX
  // at the end, let's try with ZYX and make some test
  vtkNew<vtkTransform> mappingTransform;
  mappingTransform->PostMultiply();

  // Passage from L(t_current) to L(t_begin) first frame
  // Application of the SLAM result
  mappingTransform->RotateX(rx);
  mappingTransform->RotateY(ry);
  mappingTransform->RotateZ(rz);
  double pos[3] = {tx, ty, tz};
  mappingTransform->Translate(pos);
  this->InternalInterp->AddTransform(t, mappingTransform.GetPointer());
  this->InternalInterp->Modified();
}

//-----------------------------------------------------------------------------
vtkVelodyneTransformInterpolator* vtkSlam::GetInterpolator() const
{
  return this->InternalInterp;
}

//-----------------------------------------------------------------------------
void vtkSlam::AddGeoreferencingFieldInformation(double easting0, double northing0, double height0, int utm)
{
  // add Field data to provide origin points and UTM zone
  vtkSmartPointer<vtkDoubleArray> easting = vtkSmartPointer<vtkDoubleArray>::New();
  vtkSmartPointer<vtkDoubleArray> northing = vtkSmartPointer<vtkDoubleArray>::New();
  vtkSmartPointer<vtkDoubleArray> height = vtkSmartPointer<vtkDoubleArray>::New();
  vtkSmartPointer<vtkIntArray> zone = vtkSmartPointer<vtkIntArray>::New();

  // easting
  easting->SetNumberOfTuples(1);
  easting->SetNumberOfComponents(1);
  easting->SetName("easting");
  easting->SetTuple1(0, easting0);
  this->Trajectory->GetFieldData()->AddArray(easting);

  // northing
  northing->SetNumberOfTuples(1);
  northing->SetNumberOfComponents(1);
  northing->SetName("northing");
  northing->SetTuple1(0, northing0);
  this->Trajectory->GetFieldData()->AddArray(northing);

  // easting
  height->SetNumberOfTuples(1);
  height->SetNumberOfComponents(1);
  height->SetName("height");
  height->SetTuple1(0, height0);
  this->Trajectory->GetFieldData()->AddArray(height);

  // easting
  zone->SetNumberOfTuples(1);
  zone->SetNumberOfComponents(1);
  zone->SetName("zone");
  zone->SetTuple1(0, utm);
  this->Trajectory->GetFieldData()->AddArray(zone);
}

//-----------------------------------------------------------------------------
void vtkSlam::SetInterpolator(vtkVelodyneTransformInterpolator* interpolator, double easting0, double northing0, double height0, int utm)
{
  this->SetInterpolator(interpolator);
  this->AddGeoreferencingFieldInformation(easting0, northing0, height0, utm);
}

//-----------------------------------------------------------------------------
void vtkSlam::SetInterpolator(vtkVelodyneTransformInterpolator* interpolator)
{
  // Reset the algorithm
  this->ResetAlgorithm();

  // fill the internal interpolator and
  std::vector<std::vector<double> > transforms = interpolator->GetTransformList();
  for (unsigned int k = 0; k < transforms.size(); ++k)
  {
    // time
    double t = transforms[k][0];
    // rotation
    double rx = transforms[k][1] * 180.0 / vtkMath::Pi();
    double ry = transforms[k][2] * 180.0 / vtkMath::Pi();
    double rz = transforms[k][3] * 180.0 / vtkMath::Pi();
    // position
    double x = transforms[k][4];
    double y = transforms[k][5];
    double z = transforms[k][6];

    // fill interpolator
    this->AddTransform(rx, ry, rz, x, y, z, t);

    // Add the point to the traj polyline
    this->AddDefaultPoint(x, y, z, rx, ry, rz, t);
  }

  this->Modified();
  this->Update();
}

//-----------------------------------------------------------------------------
void vtkSlam::AddDefaultPoint(double x, double y, double z, double rx, double ry, double rz, double t)
{
  this->Trajectory->GetPoints()->InsertNextPoint(x, y, z);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("time"))->InsertNextValue(t);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("roll"))->InsertNextValue(rx);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("pitch"))->InsertNextValue(ry);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("yaw"))->InsertNextValue(rz);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: intiale cost function"))->InsertNextValue(0);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: final cost function"))->InsertNextValue(0);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Variance Error"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: edges used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: planes used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: blobs used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: total keypoints used"))->InsertNextValue(0);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: intiale cost function"))->InsertNextValue(0);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: final cost function"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: edges used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: planes used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: blobs used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: total keypoints used"))->InsertNextValue(0);

  this->Orientation->GetPoints()->InsertNextPoint(rx, ry, rz);
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("time"))->InsertNextValue(t);
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("X"))->InsertNextValue(x);
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("Y"))->InsertNextValue(y);
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("Z"))->InsertNextValue(z);
}

//-----------------------------------------------------------------------------
void vtkSlam::OnlyComputeKeypoints(vtkSmartPointer<vtkPolyData> newFrame)
{
  this->PrepareDataForNextFrame();
  this->ConvertAndSortScanLines(newFrame);
  this->ComputeKeyPoints(newFrame);
}

//-----------------------------------------------------------------------------
Eigen::MatrixXd GetPolynomeApproxParam(std::vector<double>& x, std::vector<double>& y, int order)
{
  // order of the polynome
  order = order + 1;
  Eigen::MatrixXd M(x.size(), order);
  Eigen::MatrixXd Y(x.size(), 1);

  for (int sample = 0; sample < x.size(); ++sample)
  {
    for (int i = 0; i < order; ++i)
    {
      M(sample, i) = std::pow(x[sample], i);
    }
    Y(sample) = y[sample];
  }

  Eigen::MatrixXd param = (M.transpose() * M).inverse() * M.transpose() * Y;
  return param;
}

//-----------------------------------------------------------------------------
Eigen::Matrix<double, 6, 1> GetTransformsParametersForTime(double t, vtkSmartPointer<vtkVelodyneTransformInterpolator> interp)
{
  Eigen::Matrix<double, 6, 1> T;
  vtkNew<vtkTransform> corrTransform;
  interp->InterpolateTransform(t, corrTransform.Get());
  vtkNew<vtkMatrix4x4> M;
  corrTransform->GetMatrix(M.Get());
  Eigen::Matrix<double, 3, 3> R;
  Eigen::Matrix<double, 3, 1> T0, theta0;
  R << M->Element[0][0], M->Element[0][1], M->Element[0][2],
       M->Element[1][0], M->Element[1][1], M->Element[1][2],
       M->Element[2][0], M->Element[2][1], M->Element[2][2];
  T0 << M->Element[0][3], M->Element[1][3], M->Element[2][3];
  theta0(0) = std::atan2(R(2, 1), R(2, 2));
  theta0(1) = -std::asin(R(2, 0));
  theta0(2) = std::atan2(R(1, 0), R(0, 0));
  T << theta0(0), theta0(1), theta0(2), T0(0), T0(1), T0(2);
  return T;
}

//-----------------------------------------------------------------------------
Eigen::Matrix<double, 3, 1> GetVelocityForTime(double t, double dt, vtkSmartPointer<vtkVelodyneTransformInterpolator> interp)
{
  Eigen::Matrix<double, 6, 1> Tp = GetTransformsParametersForTime(t - dt, interp);
  Eigen::Matrix<double, 6, 1> Tn = GetTransformsParametersForTime(t + dt, interp);
  Eigen::Matrix<double, 6, 1> deltaT = (Tn - Tp) / (2 * dt);
  Eigen::Matrix<double, 3, 1> V;
  V << deltaT(3), deltaT(4), deltaT(5);
  return V;
}

//-----------------------------------------------------------------------------
void vtkSlam::InitTworldUsingExternalData(double adjustedTime0, double rawTime0)
{
  std::cout << "External data time range: [" << this->ExternalMeasures->GetMinimumT() << ", "
            << this->ExternalMeasures->GetMaximumT() << "]" << std::endl;

  std::cout << "proposed time: " << adjustedTime0 << " and rawtime: " << rawTime0 << std::endl;

  this->shouldBeRawTime = false;
  double t = adjustedTime0;

  // Try to compute the orientation using the adjusted time of the lidar
  // If the adjuested time is not on the bounds of the interpolator, use
  // the raw timestamp instead. This is because, depending on if a GPS
  // is connected to the lidar or not, the timestamp used change
  if (t < this->ExternalMeasures->GetMinimumT() || t > this->ExternalMeasures->GetMaximumT())
  {
    t = rawTime0;
    this->shouldBeRawTime = true;
    if (t < this->ExternalMeasures->GetMinimumT() || t > this->ExternalMeasures->GetMaximumT())
    {
      vtkGenericWarningMacro("GPS and Lidar data time interval are not consistent. Please, be sure to synchronize your devices. Slam will be computed without kalman filter");
      this->MotionModel = 0;
      return;
    }
  }

  // Initialize the slam using the GPS / IMU transform
  // that is closest (temporally) with the first lidar frame
  this->Tworld = GetTransformsParametersForTime(t, this->ExternalMeasures);

  // Initialize the slam using the GPS / IMU transform
  // that is closest (temporally) with the first lidar frame
  this->Tworld = GetTransformsParametersForTime(t, this->ExternalMeasures);
  this->PreviousTworld = Tworld;

  // Get the transforms list
  std::vector<std::vector<double> > transforms = this->ExternalMeasures->GetTransformList();
  std::vector<std::vector<double> > transformsSmoothed;
  if (transforms.size() < 10)
  {
    vtkGenericWarningMacro("Not enought external measures provided, ignore them");
    return;
  }

  // Get the average frequency (we are making the assumption that
  // the temporal samples are uniformely spaced)
  double dt = (transforms[transforms.size() - 1][0] - transforms[0][0]) / static_cast<double>(transforms.size());

  // First, smooth the trajectory provided by the GPS using a
  // degree d polynome approximation and smoothing using a
  // neighborhood of T seconds
  double tSmoothing = 3.0;
  int sampleRequired = std::ceil(tSmoothing / dt);
  int halfSize = sampleRequired / 2 + 1;

  // adapt the order of the polynome fitted
  // depending on the number of sample considered
  int order = 1;
  if (sampleRequired > 3)
  {
    order = 2;
  }
  if (sampleRequired > 6)
  {
    order = 3;
  }

  // loop other the time samples. For an entry sample,
  // approximate its neighborhood using a degree d polynome
  // and project the current sample on the fitted polynome
  for (int sample = 0; sample < transforms.size(); ++sample)
  {
    // Clamp the neighborhood support if it is
    // out of scope of the transforms support
    int minNeighIndex = std::max(0, sample - halfSize);
    int maxNeighIndex = std::min(static_cast<int>(transforms.size()) - 1, sample + halfSize);

    // Compute the timeshift to recenter the time
    double timeShift = (transforms[maxNeighIndex][0] + transforms[minNeighIndex][0]) / 2.0;
    std::vector<double> times;
    std::vector<double> valuesX, valuesY, valuesZ;

    // fill the data
    for (int neigh = minNeighIndex; neigh <= maxNeighIndex; ++neigh)
    {
      times.push_back(transforms[neigh][0] - timeShift);
      valuesX.push_back(transforms[neigh][4]);
      valuesY.push_back(transforms[neigh][5]);
      valuesZ.push_back(transforms[neigh][6]);
    }

    Eigen::MatrixXd paramX = GetPolynomeApproxParam(times, valuesX, order);
    Eigen::MatrixXd paramY = GetPolynomeApproxParam(times, valuesY, order);
    Eigen::MatrixXd paramZ = GetPolynomeApproxParam(times, valuesZ, order);

    std::vector<double> tempTransform = transforms[sample];
    double time = transforms[sample][0] - timeShift;
    tempTransform[4] = 0;
    tempTransform[5] = 0;
    tempTransform[6] = 0;
    for (int i = 0; i < paramX.rows(); ++i)
    {
      tempTransform[4] += paramX(i) * std::pow(time, i);
      tempTransform[5] += paramY(i) * std::pow(time, i);
      tempTransform[6] += paramZ(i) * std::pow(time, i);
    }
    transformsSmoothed.push_back(tempTransform);
  }

  Eigen::Matrix<double, 3, 1> NoiseVelocityMean = Eigen::Matrix<double, 3, 1>::Zero();
  Eigen::Matrix<double, 3, 3> NoiseVelocityVar = Eigen::Matrix<double, 3, 3>::Zero();
  this->VelocityNormCov = 0.0;
  double VelocityNormMean = 0.0;

  std::vector<double> Velocity, VelocityS;
  for (int k = 0; k < transforms.size(); ++k)
  {
    int indexPrev = std::max(0, k - 1);
    int indexNext = std::min(static_cast<int>(transforms.size()) - 1, k + 1);

    Eigen::Matrix<double, 3, 1> Xp, Xn, V;
    Eigen::Matrix<double, 3, 1> Xsp, Xsn, Vs;

    Xp << transforms[indexPrev][4], transforms[indexPrev][5], transforms[indexPrev][6];
    Xn << transforms[indexNext][4], transforms[indexNext][5], transforms[indexNext][6];
    V = (Xn - Xp) / (transforms[indexNext][0] - transforms[indexPrev][0]);

    Xsp << transformsSmoothed[indexPrev][4], transformsSmoothed[indexPrev][5], transformsSmoothed[indexPrev][6];
    Xsn << transformsSmoothed[indexNext][4], transformsSmoothed[indexNext][5], transformsSmoothed[indexNext][6];
    Vs = (Xsn - Xsp) / (transformsSmoothed[indexNext][0] - transformsSmoothed[indexPrev][0]);

    NoiseVelocityMean += V - Vs;
    VelocityNormMean += V.norm() - Vs.norm();
    Velocity.push_back(V.norm());
    VelocityS.push_back(Vs.norm());
  }

  VelocityNormMean /= static_cast<double>(transforms.size());
  NoiseVelocityMean /= static_cast<double>(transforms.size());
  for (int k = 0; k < transforms.size(); ++k)
  {
    int indexPrev = std::max(0, k - 1);
    int indexNext = std::min(static_cast<int>(transforms.size()) - 1, k + 1);

    Eigen::Matrix<double, 3, 1> Xp, Xn, V;
    Eigen::Matrix<double, 3, 1> Xsp, Xsn, Vs;

    Xp << transforms[indexPrev][4], transforms[indexPrev][5], transforms[indexPrev][6];
    Xn << transforms[indexNext][4], transforms[indexNext][5], transforms[indexNext][6];
    V = (Xn - Xp) / (transforms[indexNext][0] - transforms[indexPrev][0]);

    Xsp << transformsSmoothed[indexPrev][4], transformsSmoothed[indexPrev][5], transformsSmoothed[indexPrev][6];
    Xsn << transformsSmoothed[indexNext][4], transformsSmoothed[indexNext][5], transformsSmoothed[indexNext][6];
    Vs = (Xsn - Xsp) / (transformsSmoothed[indexNext][0] - transformsSmoothed[indexPrev][0]);

    this->VelocityNormCov += std::pow(V.norm() - Vs.norm() - VelocityNormMean, 2);
    NoiseVelocityVar += ((V - Vs) - NoiseVelocityMean) * ((V - Vs) - NoiseVelocityMean).transpose();
  }
  this->VelocityNormCov /= static_cast<double>(transforms.size());
  NoiseVelocityVar /= static_cast<double>(transforms.size());

  // Now, making the ergodic assumption of the signal's noise
  // we will estimate the mean and the standard deviation
  // of the GPS signal by analyzing the difference between
  // our regression and the raw data
  Eigen::Matrix<double, 3, 1> NoiseMean = Eigen::Matrix<double, 3, 1>::Zero();
  Eigen::Matrix<double, 3, 3> NoiseVar = Eigen::Matrix<double, 3, 3>::Zero();

  // Compute the mean of the noise
  for (int k = 0; k < transforms.size(); ++k)
  {
    Eigen::Matrix<double, 3, 1> X, Xs;
    X << transforms[k][4], transforms[k][5], transforms[k][6];
    Xs << transformsSmoothed[k][4], transformsSmoothed[k][5], transformsSmoothed[k][6];
    NoiseMean += X - Xs;
  }
  NoiseMean /= static_cast<double>(transforms.size());

  // compute the variance covariance of the noise
  for (int k = 0; k < transforms.size(); ++k)
  {
    Eigen::Matrix<double, 3, 1> X, Xs;
    X << transforms[k][4], transforms[k][5], transforms[k][6];
    Xs << transformsSmoothed[k][4], transformsSmoothed[k][5], transformsSmoothed[k][6];
    NoiseVar += ((X - Xs) - NoiseMean) * ((X - Xs) - NoiseMean).transpose();
  }
  NoiseVar /= static_cast<double>(transforms.size());

  // Now, initialize the Kalman Filter Covariance
  // and initial vector state regarding the date
  // provided by the GPS / IMU sensor.
  Eigen::Matrix<double, 12, 12> Cov = Eigen::Matrix<double, 12, 12>::Ones();
  Eigen::Matrix<double, 12, 1> StateVector = Eigen::Matrix<double, 12, 1>::Zero();

  // We have an idea of the position covariance due to
  // the previous noise estimation step
  for (unsigned int i = 0; i < 3; ++i)
  {
    for (unsigned int j = 0; j < 3; ++j)
    {
      Cov(i + 3, j + 3) = 10.0 * NoiseVar(i, j);
      Cov(i + 9, j + 9) = 10.0 * NoiseVelocityVar(i, j);
    }
  }

  // Fill state vector using the initial position
  for (unsigned int k = 0; k < 6; ++k)
  {
    StateVector(k) = this->Tworld(k);
  }
  Eigen::Matrix<double, 3, 1> V = GetVelocityForTime(t, 1.5, this->ExternalMeasures);
  StateVector(9) = V(0);
  StateVector(10) = V(1);
  StateVector(11) = V(2);

  this->KalmanEstimator.SetInitialStatevector(StateVector, Cov);
  std::cout << "order: " << order << std::endl;
  std::cout << "sampleRequired: " << sampleRequired << std::endl;
  std::cout << "Noise Mean: " << std::endl << NoiseMean << std::endl;
  std::cout << "Noise Variance: " << std::endl << NoiseVar << std::endl;
  std::cout << "Noise Velocity Mean: " << std::endl << NoiseVelocityMean << std::endl;
  std::cout << "Noise Velocity Variance: " << std::endl << NoiseVelocityVar << std::endl;
  std::cout << "State Vector covariance: " << std::endl << Cov << std::endl;
  std::cout << "Velocity norm mean: " << std::endl << VelocityNormMean << std::endl;
  std::cout << "Velocity norm cov: " << std::endl << this->VelocityNormCov << std::endl;
}

//-----------------------------------------------------------------------------
void vtkSlam::AddFrame(vtkPolyData* newFrame)
{
  if (!newFrame)
  {
    vtkGenericWarningMacro("Slam entry is a null pointer data");
    return;
  }
  this->vtkCurrentFrame = newFrame;

  // Check if the number of lasers has been set
  if (this->NLasers == 0)
  {
    vtkGenericWarningMacro("Frame added without specifying the number of lasers");
  }

  std::cout << "#########################################################" << std::endl
            << "Processing frame : " << this->NbrFrameProcessed << std:: endl
            << "#########################################################" << std::endl
            << std::endl;

  // Check if external measures have been
  // provided to the slam algorithm
  double adjuestedTime0 = newFrame->GetPointData()->GetArray("adjustedtime")->GetTuple1(0) * 1e-6;
  double rawTime0 = static_cast<double>(newFrame->GetPointData()->GetArray("timestamp")->GetTuple1(0)) * 1e-6;
  if (this->ExternalMeasures && (this->NbrFrameProcessed == 0))
  {
    vtkGenericWarningMacro("External data provided to the SLAM");
    this->InitTworldUsingExternalData(adjuestedTime0, rawTime0);
  }

  if (this->shouldBeRawTime)
    this->CurrentTime = rawTime0;
  else
    this->CurrentTime = adjuestedTime0;

  // Reset the members variables used during the last
  // processed frame so that they can be used again
  PrepareDataForNextFrame();

  // Update the kalman filter time
  double time = newFrame->GetPointData()->GetArray("adjustedtime")->GetTuple1(0) * 1e-6;
  this->KalmanEstimator.SetCurrentTime(time);

  // If the new frame is the first one we just add the
  // extracted keypoints into the map without running
  // odometry and mapping steps
  if (this->NbrFrameProcessed == 0)
  {
    // print parameters to provide some information
    this->PrintParameters();

    // Convert the new frame into pcl format and sort
    // the laser scan-lines by vertical angle
    this->ConvertAndSortScanLines(newFrame);

    // Compute the edges and planars keypoints
    this->ComputeKeyPoints(newFrame);

    // update map using tworld
    this->UpdateMapsUsingTworld();

    // Current keypoints become previous ones
    this->PreviousEdgesPoints = this->CurrentEdgesPoints;
    this->PreviousPlanarsPoints = this->CurrentPlanarsPoints;
    this->PreviousBlobsPoints = this->CurrentBlobsPoints;
    this->NbrFrameProcessed++;

    this->AddTransform(rawTime0);
    return;
  }

  // Convert the new frame into pcl format and sort
  // the laser scan-lines by vertical angle
  InitTime();
  this->ConvertAndSortScanLines(vtkCurrentFrame);
  StopTimeAndDisplay("Sorting lines");

  // Compute the edges and planars keypoints
  InitTime();
  this->ComputeKeyPoints(vtkCurrentFrame);
  StopTimeAndDisplay("Keypoints extraction");

  // Perfom EgoMotion
  InitTime();
  this->ComputeEgoMotion();
  StopTimeAndDisplay("Ego-Motion");

  // Transform the current keypoints to the
  // referential of the sensor at the end of
  // frame acquisition
  InitTime();
  //this->TransformCurrentKeypointsToEnd();
  StopTimeAndDisplay("Undistortion");

  // Perform Mapping
  InitTime();
  this->Mapping();
  StopTimeAndDisplay("Mapping");

  // Current keypoints become previous ones
  this->PreviousEdgesPoints = this->CurrentEdgesPoints;
  this->PreviousPlanarsPoints = this->CurrentPlanarsPoints;
  this->PreviousBlobsPoints = this->CurrentBlobsPoints;
  this->NbrFrameProcessed++;

  // Information
  Eigen::Matrix<double, 3, 1> angles, trans;

  angles << Rad2Deg(this->Trelative(0)), Rad2Deg(this->Trelative(1)), Rad2Deg(this->Trelative(2));
  trans << this->Trelative(3), this->Trelative(4), this->Trelative(5);
  std::cout << "Odometry : " << std::endl;
  std::cout << "angles : " << std::endl << angles << std::endl;
  std::cout << "trans : " << std::endl << trans << std::endl;

  angles << Rad2Deg(this->Tworld(0)), Rad2Deg(this->Tworld(1)), Rad2Deg(this->Tworld(2));
  trans << this->Tworld(3), this->Tworld(4), this->Tworld(5);
  std::cout << "World : " << std::endl;
  std::cout << "angles : " << std::endl << angles << std::endl;
  std::cout << "trans : " << std::endl << trans << std::endl;


  // Update Filter output
  // Update trajectory points, the cells are construct in the request Data
  this->Trajectory->GetPoints()->InsertNextPoint(this->Tworld[3], this->Tworld[4], this->Tworld[5]);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("time"))->InsertNextValue(newFrame->GetPointData()->GetArray("timestamp")->GetTuple1(0));
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("pitch"))->InsertNextValue(this->Tworld[0]);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("roll"))->InsertNextValue(this->Tworld[1]);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("yaw"))->InsertNextValue(this->Tworld[2]);

  // Update orientation points, the cell are construct in the request data
  this->Orientation->GetPoints()->InsertNextPoint(this->Tworld[0], this->Tworld[1], this->Tworld[2]);
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("time"))->InsertNextValue(newFrame->GetPointData()->GetArray("timestamp")->GetTuple1(0));
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("X"))->InsertNextValue(this->Tworld[3]);
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("Y"))->InsertNextValue(this->Tworld[4]);
  static_cast<vtkDoubleArray*>(this->Orientation->GetPointData()->GetArray("Z"))->InsertNextValue(this->Tworld[5]);

  // Indicate the filter has been modify
  this->Modified();
  this->AddTransform(rawTime0);
  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::LoadTransforms(const std::string& filename)
{
  // Reset the algorithm
  this->ResetAlgorithm();

  std::ifstream file;
  file.open(filename);

  if (!file.is_open())
  {
    vtkGenericWarningMacro("Can't load the specified file");
  }

  std::string line, header;
  std::string expectedLine = "Time,Rx(Roll),Ry(Pitch),Rz(Yaw),X,Y,Z";
  std::string expectedLine2 = "Time,Rx(Roll),Ry(Pitch),Rz(Yaw),X,Y,Z,easting,northing,height,utm";
  std::getline(file, header);
  if (header != expectedLine && header != expectedLine2)
  {
    vtkGenericWarningMacro("Header file not expected. Version incompability");
  }

  bool shouldReadGeorefData = (header == expectedLine2);
  while (std::getline(file, line))
  {
    std::vector<std::string> values;
    boost::split(values, line, boost::is_any_of(","));

    // time
    double t = std::atof(values[0].c_str());
    // rotation
    double rx = std::atof(values[1].c_str()) * 180.0 / vtkMath::Pi();
    double ry = std::atof(values[2].c_str()) * 180.0 / vtkMath::Pi();
    double rz = std::atof(values[3].c_str()) * 180.0 / vtkMath::Pi();
    // position
    double x = std::atof(values[4].c_str());
    double y = std::atof(values[5].c_str());
    double z = std::atof(values[6].c_str());

    // fill interpolator
    this->AddTransform(rx, ry, rz, x, y, z, t);

    // Add default point to traj polyline
    this->AddDefaultPoint(x, y, z, rx, ry, rz, t);

    // get the georeferencing data
    if (shouldReadGeorefData)
    {
      vtkGenericWarningMacro("Slam data loaded are georeferenced");
      shouldReadGeorefData = false;
      double easting0 = std::atof(values[7].c_str());
      double northing0 = std::atof(values[8].c_str());
      double height0 = std::atof(values[9].c_str());
      int utm = std::atoi(values[10].c_str());
      this->AddGeoreferencingFieldInformation(easting0, northing0, height0, utm);
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::ConvertAndSortScanLines(vtkSmartPointer<vtkPolyData> input)
{
  // temp var
  double xL[3]; // in {L}
  Point yL; // in {L}

  // Get informations about input pointcloud
  vtkDataArray* lasersId = input->GetPointData()->GetArray("laser_id");
  vtkDataArray* time = input->GetPointData()->GetArray("timestamp");
  vtkPoints* Points = input->GetPoints();
  unsigned int Npts = input->GetNumberOfPoints();
  double t0 = static_cast<double>(time->GetTuple1(0));
  double t1 = static_cast<double>(time->GetTuple1(Npts - 1));
  this->FromVTKtoPCLMapping.resize(Npts);


  for (unsigned int index = 0; index < Npts; ++index)
  {
    // Get information about current point
    Points->GetPoint(index, xL);
    yL.x = xL[0];
    yL.y = xL[1];
    yL.z = xL[2];

    double relAdv = (static_cast<double>(time->GetTuple1(index)) - t0) / (t1 - t0);
    unsigned int id = static_cast<int>(lasersId->GetTuple1(index));
    id = this->LaserIdMapping[id];
    yL.intensity = relAdv;
    yL.normal_y = id;

    // add the current point to its corresponding laser scan
    this->pclCurrentFrame->push_back(yL);
    this->pclCurrentFrameByScan[id]->push_back(yL);
    this->FromVTKtoPCLMapping[index] = std::pair<int, int>(id, this->pclCurrentFrameByScan[id]->size() - 1);
    this->FromPCLtoVTKMapping[id].push_back(index);
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeKeyPoints(vtkSmartPointer<vtkPolyData> input)
{
  // Initialize the vectors with the correct length
  for (unsigned int k = 0; k < this->NLasers; ++k)
  {
    this->IsPointValid[k].resize(this->pclCurrentFrameByScan[k]->size(), 1);
    this->Label[k].resize(this->pclCurrentFrameByScan[k]->size(), 0);
    this->Angles[k].resize(this->pclCurrentFrameByScan[k]->size(),0);
    this->DepthGap[k].resize(this->pclCurrentFrameByScan[k]->size(), 0);
    this->BlobScore[k].resize(this->pclCurrentFrameByScan[k]->size(), 0);
  }

  // compute keypoints scores
  this->ComputeCurvature(input);

  // Invalid points with bad criteria
  this->InvalidPointWithBadCriteria();

  // labelize keypoints
  this->SetKeyPointsLabels(input);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeCurvature(vtkSmartPointer<vtkPolyData> input)
{
  Point currentPoint;
  Eigen::Matrix<double, 3, 1> X, U, V, Pleft, Pright;
  Eigen::Matrix<double, 3, 1> Nleft, Nright, centralPoint;
  Eigen::Matrix<double, 3, 1> dirGapLeft, dirGapRight;
  Eigen::Matrix<double, 3, 3> Dleft, Dright;
  double distCandidate;
  LineFitting leftLine;
  LineFitting rightLine;

  // loop over scans lines
  for (unsigned int scanLine = 0; scanLine < this->NLasers; ++scanLine)
  {
    // loop over points in the current scan line
    int Npts = this->pclCurrentFrameByScan[scanLine]->size();

    // if the line is almost empty, skip it
    if (Npts < 3 * this->NeighborWidth)
    {
      continue;
    }

    for (int index = this->NeighborWidth; index < Npts - this->NeighborWidth - 1; ++index)
    {
      // central point
      currentPoint = this->pclCurrentFrameByScan[scanLine]->points[index];
      centralPoint << currentPoint.x, currentPoint.y, currentPoint.z;

      // We will compute the line that fit the neighbors located
      // previously the current. We will do the same for the
      // neighbors located after the current points. We will then
      // compute the angle between these two lines as an approximation
      // of the "sharpness" of the current point.
      std::vector<Eigen::Matrix<double, 3, 1> > leftNeighbor;
      std::vector<Eigen::Matrix<double, 3, 1> > rightNeighbor;

      // Fill right and left neighborhood
      for (int j = index - this->NeighborWidth; j <= index + this->NeighborWidth; ++j)
      {
        currentPoint = this->pclCurrentFrameByScan[scanLine]->points[j];
        X << currentPoint.x, currentPoint.y, currentPoint.z;
        if (j < index)
          leftNeighbor.push_back(X);
        if (j > index)
          rightNeighbor.push_back(X);
      }

      // Fit line on the neighborhood
      leftLine.FitFast(leftNeighbor);
      rightLine.FitFast(rightNeighbor);


      Pleft = leftLine.Position;
      Nleft = leftLine.Direction;
      Dleft = leftLine.SemiDist;

      Pright = rightLine.Position;
      Nright = rightLine.Direction;
      Dright = rightLine.SemiDist;

      // Indicate if the left and right side
      // neighborhood of the current point is flat or not
      bool leftFlat = true;
      bool rightFlat = true;

      // Measurement of the gap
      double minDistLeft = std::numeric_limits<double>::max();
      double minDistRight = std::numeric_limits<double>::max();

      // Compute the fitting line and estimate
      // if the neighborhood is flat
      for (int j = index - this->NeighborWidth; j <= index + this->NeighborWidth; ++j)
      {
        currentPoint = this->pclCurrentFrameByScan[scanLine]->points[j];
        X << currentPoint.x, currentPoint.y, currentPoint.z;

        if (j < index)
        {
          distCandidate = (X - centralPoint).norm() / centralPoint.norm();
          if (distCandidate < minDistLeft)
          {
            minDistLeft = distCandidate;
            dirGapLeft = (X - centralPoint).normalized();
          }

          // if a point of the neighborhood is too far from
          // the fitting line we considere the neighborhood as
          // non flat
          double d = std::sqrt((X - Pleft).transpose() * Dleft * (X - Pleft));
          if (d > 0.02)
          {
            leftFlat = false;
          }
        }
          
        if (j > index)
        {
          distCandidate = (X - centralPoint).norm() / centralPoint.norm();
          if (distCandidate < minDistRight)
          {
            minDistRight = distCandidate;
            dirGapRight = (X - centralPoint).normalized();
          }

          // if a point of the neighborhood is too far from
          // the fitting line we considere the neighborhood as
          // non flat
          double d = std::sqrt((X - Pright).transpose() * Dright * (X - Pright));
          if (d > 0.02)
          {
            rightFlat = false;
          }
        }
      }

      double dist1 = 0;
      double dist2 = 0;

      // if both neighborhood are flat we can compute
      // the angle between them as an approximation of the
      // sharpness of the current point
      if (rightFlat && leftFlat)
      {
        this->Angles[scanLine][index] = std::abs((Nleft.cross(Nright)).norm()); // sin of angle actually

        dist1 = std::abs(dirGapLeft.cross(Nleft).norm()) * minDistLeft;
        dist2 = std::abs(dirGapRight.cross(Nright).norm()) * minDistRight;
      }
      // Here one side of the neighborhood is non flat
      // Hence it is not worth to estimate the sharpness.
      // Only the gap will be considered here.
      else if (rightFlat && !leftFlat)
      {
        dist1 = minDistLeft;
        dist2 = std::abs(dirGapRight.cross(Nright).norm()) * minDistRight;
      }
      else if (!rightFlat && leftFlat)
      {
        dist1 = std::abs(dirGapLeft.cross(Nleft).norm()) * minDistLeft;
        dist2 = minDistRight;
      }
      else
      {
        dist1 = 0.5 * minDistLeft; // 0.5: minor trust
        dist2 = 0.5 * minDistRight;
        this->BlobScore[scanLine][index] = 1;
      }
      this->DepthGap[scanLine][index] = std::max(dist1, dist2);
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::InvalidPointWithBadCriteria()
{
  // Temporary variables used in the next loop
  Eigen::Matrix<double, 3, 1> dX, X, Xn, Xp, Xproj, dXproj;
  Eigen::Matrix<double, 3, 1> Y, Yn, Yp, dY;
  double dL, L, Ln, expectedLength, dLn, dLp, expectedLengthNeighbor;
  Point currentPoint, nextPoint, previousPoint;
  Point temp;

  // loop over scan lines
  for (unsigned int scanLine = 0; scanLine < this->NLasers; ++scanLine)
  {
    int Npts = this->pclCurrentFrameByScan[scanLine]->size();

    // if the line is almost empty, skip it
    if (Npts < 3 * this->NeighborWidth)
    {
      continue;
    }
    // invalidate first and last points
    for (int index = 0; index <= this->NeighborWidth; ++index)
    {
      this->IsPointValid[scanLine][index] = 0;
    }
    for (int index = Npts - 1 - this->NeighborWidth - 1; index < Npts; ++index)
    {
      this->IsPointValid[scanLine][index] = 0;
    }

    // loop over points into the scan line
    for (int index = this->NeighborWidth; index <  Npts - this->NeighborWidth - 1; ++index)
    {
      currentPoint = this->pclCurrentFrameByScan[scanLine]->points[index];
      nextPoint = this->pclCurrentFrameByScan[scanLine]->points[index + 1];
      previousPoint = this->pclCurrentFrameByScan[scanLine]->points[index - 1];
      X << currentPoint.x, currentPoint.y, currentPoint.z;
      Xn << nextPoint.x, nextPoint.y, nextPoint.z;
      Xp << previousPoint.x, previousPoint.y, previousPoint.z;
      dX = Xn - X;
      L = X.norm();
      Ln = Xn.norm();
      dLn = dX.norm();

      // the expected length between two firing of the same laser
      // depend on the distance and the angular resolution of the
      // sensor.
      expectedLength = 2.0 *  std::tan(this->AngleResolution / 2.0) * L;
      double ratioExpectedLength = 10.0;

      // if the length between the two firing
      // if more than n-th the expected length
      // it means that there is a gap. We now must
      // determine if the gap is due to the geometry of
      // the scene or if the gap is due to an occluded area
      if (dLn > ratioExpectedLength * expectedLength)
      {
        // Project the next point onto the
        // sphere of center 0 and radius =
        // norm of the current point. If the
        // gap has disappeared it means that
        // the gap was due to an occlusion
        Xproj = L / Ln * Xn;
        dXproj = Xproj - X;
        // it is a depth gap, invalidate the part which belong
        // to the occluded area (farest)
        // invalid next part
        if (L < Ln)
        {
          for (unsigned int i = index + 1; i <= index + this->NeighborWidth; ++i)
          {
            if (i > index + 1)
            {
              temp = this->pclCurrentFrameByScan[scanLine]->points[i - 1];
              Yp << temp.x, temp.y, temp.z;
              temp = this->pclCurrentFrameByScan[scanLine]->points[i];
              Y << temp.x, temp.y, temp.z;
              dY = Y - Yp;
              expectedLengthNeighbor = 2.0 *  std::tan(this->AngleResolution / 2.0) * Y.norm();
              // if there is a gap in the neihborhood
              // we do not invalidate the rest of neihborhood
              if (dY.norm() > ratioExpectedLength * expectedLength)
              {
                break;
              }
            }
            this->IsPointValid[scanLine][i] = 0;
          }
        }
        // invalid previous part
        else
        {
          for (unsigned int i = index - this->NeighborWidth; i <= index; ++i)
          {
            if (i < index)
            {
              temp = this->pclCurrentFrameByScan[scanLine]->points[i + 1];
              Yn << temp.x, temp.y, temp.z;
              temp = this->pclCurrentFrameByScan[scanLine]->points[i];
              Y << temp.x, temp.y, temp.z;
              dY = Yn - Y;
              expectedLengthNeighbor = 2.0 *  std::tan(this->AngleResolution / 2.0) * Y.norm();
              // if there is a gap in the neihborhood
              // we do not invalidate the rest of neihborhood
              if (dY.norm() > ratioExpectedLength * expectedLength)
              {
                break;
              }
            }
            this->IsPointValid[scanLine][i] = 0;
          }
        }
      }
      // Invalid points which are too close from the sensor
      if (L < this->MinDistanceToSensor)
      {
        this->IsPointValid[scanLine][index] = 0;
      }

      // Invalid points which are on a planar
      // surface nearly parallel to the laser
      // beam direction
      dLp = (X - Xp).norm();
      if ((dLp > 1 / 4.0 * ratioExpectedLength * expectedLength) && (dLn > 1 / 4.0 * ratioExpectedLength * expectedLength))
      {
        this->IsPointValid[scanLine][index] = 0;
      }
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::SetKeyPointsLabels(vtkSmartPointer<vtkPolyData> input)
{
  std::vector<std::pair<int, int> > edgesIndex;
  std::vector<std::pair<int, int> > planarIndex;
  std::vector<std::pair<int, int> > blobIndex;

  std::cout << "extracting with: " << this->MaxEdgePerScanLine << " MaxEdgePerScanLine" << std::endl;
  std::cout << "extracting with: " << this->MaxPlanarsPerScanLine << " MaxPlanarsPerScanLine" << std::endl;

  // loop over the scan lines
  for (unsigned int scanLine = 0; scanLine < this->NLasers; ++scanLine)
  {
    int Npts = this->pclCurrentFrameByScan[scanLine]->size();
    unsigned int nbrEdgePicked = 0;
    unsigned int nbrPlanarPicked = 0;

    // We split the validity of points between the edges
    // keypoints and planar keypoints. This allows to take
    // some points as planar keypoints even if they are close
    // to an edge keypoint. 
    std::vector<int> IsPointValidForPlanar = this->IsPointValid[scanLine];

    // if the line is almost empty, skip it
    if (Npts < 3 * this->NeighborWidth)
    {
      continue;
    }

    // Sort the curvature score in a decreasing order
    std::vector<size_t> sortedDepthGapIdx = sortIdx<double>(this->DepthGap[scanLine]);
    std::vector<size_t> sortedAnglesIdx = sortIdx<double>(this->Angles[scanLine]);
    std::vector<size_t> sortedBlobScoreIdx = sortIdx<double>(this->BlobScore[scanLine]);

    double depthGap = 0;
    double sinAngle = 0;
    double blobScore = 0;
    int index = 0;

    // Edges using depth gap
    for (int k = 0; k < Npts; ++k)
    {
      index = sortedDepthGapIdx[k];
      depthGap = this->DepthGap[scanLine][index];

      // max keypoints reached
      if (nbrEdgePicked >= this->MaxEdgePerScanLine)
      {
        break;
      }

      // thresh
      if (depthGap < this->EdgeDepthGapThreshold)
      {
        break;
      }

      // if the point is invalid continue
      if (this->IsPointValid[scanLine][index] == 0)
      {
        continue;
      }

      // else indicate that the point is an edge
      this->Label[scanLine][index] = 4;
      edgesIndex.push_back(std::pair<int, int>(scanLine, index));
      nbrEdgePicked++;
      //IsPointValidForPlanar[index] = 0;

      // invalid its neighborhod
      int indexBegin = index - this->NeighborWidth + 1;
      int indexEnd = index + this->NeighborWidth - 1;
      indexBegin = std::max(0, indexBegin);
      indexEnd = std::min(Npts - 1, indexEnd);
      for (int j = indexBegin; j <= indexEnd; ++j)
      {
        this->IsPointValid[scanLine][j] = 0;
      }
    }

    // Edges using angles
    for (int k = 0; k < Npts; ++k)
    {
      index = sortedAnglesIdx[k];
      sinAngle = this->Angles[scanLine][index];

      // max keypoints reached
      if (nbrEdgePicked >= this->MaxEdgePerScanLine)
      {
        break;
      }

      // thresh
      if (sinAngle < this->EdgeSinAngleThreshold)
      {
        break;
      }

      // if the point is invalid continue
      if (this->IsPointValid[scanLine][index] == 0)
      {
        continue;
      }

      // else indicate that the point is an edge
      this->Label[scanLine][index] = 4;
      edgesIndex.push_back(std::pair<int, int>(scanLine, index));
      nbrEdgePicked++;
      //IsPointValidForPlanar[index] = 0;

      // invalid its neighborhod
      int indexBegin = index - this->NeighborWidth;
      int indexEnd = index + this->NeighborWidth;
      indexBegin = std::max(0, indexBegin);
      indexEnd = std::min(Npts - 1, indexEnd);
      for (int j = indexBegin; j <= indexEnd; ++j)
      {
        this->IsPointValid[scanLine][j] = 0;
      }
    }

    // Blobs Points
    if (!this->FastSlam)
    {
      for (int k = 0; k < Npts; ++k)
      {
        blobIndex.push_back(std::pair<int, int>(scanLine, k));
      }
    }

    // Planes
    for (int k = Npts - 1; k >= 0; --k)
    {
      index = sortedAnglesIdx[k];
      sinAngle = this->Angles[scanLine][index];

      // max keypoints reached
      if (nbrPlanarPicked >= this->MaxPlanarsPerScanLine)
      {
        //break;
      }

      // thresh
      if (sinAngle > this->PlaneSinAngleThreshold)
      {
        break;
      }

      // if the point is invalid continue
      if (IsPointValidForPlanar[index] == 0)
      {
        continue;
      }

      // else indicate that the point is a planar one
      if ((this->Label[scanLine][index] != 4) && (this->Label[scanLine][index] != 3))
        this->Label[scanLine][index] = 2;
      planarIndex.push_back(std::pair<int, int>(scanLine, index));
      IsPointValidForPlanar[index] = 0;
      this->IsPointValid[scanLine][index] = 0;

      // Invalid its neighbor so that we don't have too
      // many planar keypoints in the same region. This is
      // required because of the k-nearest search + plane
      // approximation realized in the odometry part. Indeed,
      // if tall the planar points are on the same scan line the
      //  problem is degenerated since all the points are distributed
      // on a line.
      int indexBegin = index - 4;
      int indexEnd = index + 4;
      indexBegin = std::max(0, indexBegin);
      indexEnd = std::min(Npts - 1, indexEnd);
      for (int j = indexBegin; j <= indexEnd; ++j)
      {
        IsPointValidForPlanar[j] = 0;
      }
      nbrPlanarPicked++;
    }
  }

  // add keypoints in increasing scan id order
  std::sort(edgesIndex.begin(), edgesIndex.end());
  std::sort(planarIndex.begin(), planarIndex.end());
  std::sort(blobIndex.begin(), blobIndex.end());

  // fill the keypoints vectors and compute the max dist keypoints
  this->FarestKeypointDist = 0.0;
  Point p;
  for (unsigned int k = 0; k < edgesIndex.size(); ++k)
  {
    p = this->pclCurrentFrameByScan[edgesIndex[k].first]->points[edgesIndex[k].second];
    this->CurrentEdgesPoints->push_back(p);
    this->FarestKeypointDist = std::max(this->FarestKeypointDist, static_cast<double>(std::sqrt(std::pow(p.x, 2) + std::pow(p.y, 2) + std::pow(p.z, 2))));
  }
  for (unsigned int k = 0; k < planarIndex.size(); ++k)
  {
    p = this->pclCurrentFrameByScan[planarIndex[k].first]->points[planarIndex[k].second];
    this->CurrentPlanarsPoints->push_back(p);
    this->FarestKeypointDist = std::max(this->FarestKeypointDist, static_cast<double>(std::sqrt(std::pow(p.x, 2) + std::pow(p.y, 2) + std::pow(p.z, 2))));
  }
  for (unsigned int k = 0; k < blobIndex.size();  ++k)
  {
    p = this->pclCurrentFrameByScan[blobIndex[k].first]->points[blobIndex[k].second];
    this->CurrentBlobsPoints->push_back(p);
    this->FarestKeypointDist = std::max(this->FarestKeypointDist, static_cast<double>(std::sqrt(std::pow(p.x, 2) + std::pow(p.y, 2) + std::pow(p.z, 2))));
  }

  std::cout << "Extracted : " << this->CurrentEdgesPoints->size() << " : edges points" << std::endl;
  std::cout << "Extracted : " << this->CurrentPlanarsPoints->size() << " : planars points" << std::endl;
  std::cout << "Extracted : " << this->CurrentBlobsPoints->size() << " : Blobs points" << std::endl;
}

//-----------------------------------------------------------------------------
void vtkSlam::TransformToWorld(Point& p, Eigen::Matrix<double, 6, 1>& T)
{
  // Rotation and translation and points
  Eigen::Matrix<double, 3, 3> Rw;
  Eigen::Matrix<double, 3, 1> Tw;
  Eigen::Matrix<double, 3, 1> P;

  Rw = GetRotationMatrix(T);
  Tw << T(3), T(4), T(5);
  P << p.x, p.y, p.z;

  P = Rw * P + Tw;

  p.x = P(0);
  p.y = P(1);
  p.z = P(2);
}

//-----------------------------------------------------------------------------
void vtkSlam::FindEdgeLineMatch(Point p, pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges,
                                std::vector<int>& matchEdgeIndex1, std::vector<int>& matchEdgeIndex2, int currentEdgeIndex,
                                Eigen::Matrix<double, 3, 3> R, Eigen::Matrix<double, 3, 1> dT)
{
  // transform point using current estimation
  Eigen::Matrix<double, 3, 1> P;
  P << p.x, p.y, p.z;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);

  Point p1, p2;
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  
  // Search the nearests points of the current point reprojected
  // nearestIndex is the index of the nearest pointsd found
  // nearestDist is their corresponding distances
  kdtreePreviousEdges->nearestKSearch(p, 1, nearestIndex, nearestDist);

  // closest point index
  int closestPointIndex = -1;
  int secondPointIndex = -1;
  matchEdgeIndex1[currentEdgeIndex] = -1;
  matchEdgeIndex2[currentEdgeIndex] = -1;

  // max distance allowed between two frames. It depends on the
  // sensor speed and the sensor RPM. It is not automatically computed
  // the value of MaxDistBetweenTwoFrames should be set. By default
  // it is set to 2.5 meters (90 km/h at 600 RPM)
  if (static_cast<double>(nearestDist[0]) < this->MaxDistBetweenTwoFrames)
  {
    // take the closest point
    closestPointIndex = nearestIndex[0];
    p1 = this->PreviousEdgesPoints->points[closestPointIndex];

    // Avoid SegFault when the kd-tree doesn't find the cloest point
    // it is due to a point p with -1.#IND values sometimes
    if(closestPointIndex > this->PreviousEdgesPoints->size()-1)
    {
      std::cout << "Edges correspondances error" << std::endl;
      std::cout << "closestPointInd : " << closestPointIndex << std::endl;
      std::cout << "point : [" << p.x << ";" << p.y << ";" << p.z << "]" << std::endl;
      return;
    }

    // get the ID of the closest scan line of the closest point
    int iD = p1.normal_y;

    // VLP-16: 2 scan line gap
    // VLP-32: 4 scan line gap
    // HDL-64: 8 scan line gap
    int maxScanIdStep = this->NLasers / 8;
    double minDist = 2.0 * this->MaxDistBetweenTwoFrames;

    // now find the second closest point that belong to an other
    // scan line. The keypoints are sorted using scan id.
    for (int pointIndex = closestPointIndex + 1; pointIndex < this->PreviousEdgesPoints->size(); ++pointIndex)
    {
      if (pointIndex > this->PreviousEdgesPoints->size() - 1)
      {
        break;
      }

      Point candidate = this->PreviousEdgesPoints->points[pointIndex];
      bool shouldSkip = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) > iD + maxScanIdStep;

      if (shouldBreak)
      {
        break;
      }
      if (!shouldSkip)
      {
        // compute the distance
        double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);
        if (dist < minDist)
        {
          minDist = dist;
          secondPointIndex = pointIndex;
        }
      }
    }
    for (int pointIndex = closestPointIndex - 1; pointIndex >= 0; --pointIndex)
    {
      if (pointIndex < 0)
      {
        break;
      }

      Point candidate = this->PreviousEdgesPoints->points[pointIndex];
      bool shouldSkip = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) < iD - maxScanIdStep;
      if (shouldBreak)
      {
        break;
      }
      if (!shouldSkip)
      {
        // compute the distance
        double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);

        if (dist < minDist)
        {
          minDist = dist;
          secondPointIndex = pointIndex;
        }
      }
    }
  }
  else
  {
    return;
  }

  if (secondPointIndex == -1)
  {
    return;
  }

  matchEdgeIndex1[currentEdgeIndex] = closestPointIndex;
  matchEdgeIndex2[currentEdgeIndex] = secondPointIndex;
  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::FindPlaneMatch(Point p, pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousPlanes,
                      std::vector<int>& matchPlaneIndex1, std::vector<int>& matchPlaneIndex2,
                      std::vector<int>& matchPlaneIndex3, int currentPlaneIndex,
                      Eigen::Matrix<double, 3, 3> R, Eigen::Matrix<double, 3, 1> dT)
{
  // transform point using current estimation
  Eigen::Matrix<double, 3, 1> P;
  P << p.x, p.y, p.z;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);

  Point p1, p2, p3;
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;

  // Here we are looking for 3 points to define a plane. The first one is the closest point 
  // of the current planar point. The two others are the minPoint in the same scan and in another scan
  int closestPointIndex = -1;
  int secondPointIndex = -1;
  int thirdPointIndex = -1;

  // reset previous index
  matchPlaneIndex1[currentPlaneIndex] = -1;
  matchPlaneIndex2[currentPlaneIndex] = -1;
  matchPlaneIndex3[currentPlaneIndex] = -1;

  // Find the closest point
  kdtreePreviousPlanes->nearestKSearch(p, 1, nearestIndex, nearestDist);

  // max distance allowed between two frames. It depends on the
  // sensor speed and the sensor RPM. It is not automatically computed
  // the value of MaxDistBetweenTwoFrames should be set. By default
  // it is set to 2.5 meters (90 km/h at 600 RPM)
  if (static_cast<double>(nearestDist[0]) < 2.0 * this->MaxDistBetweenTwoFrames)
  {
    closestPointIndex = nearestIndex[0];
    if(closestPointIndex > this->PreviousPlanarsPoints->size() - 1 || closestPointIndex < 0)
    {
      std::cout << "Flat correspondances error" << std::endl;
      std::cout << "closestPointInd : " << closestPointIndex << std::endl;
      std::cout << "point : [" << p.x << ";" << p.y << ";" << p.z << "]" << std::endl;
      return;
    }

    p1 = this->PreviousPlanarsPoints->points[closestPointIndex];

    // We get the id of the closest scan laser line
    int iD = p1.normal_y; 

    // VLP-16: 2 scan line gap
    // VLP-32: 4 scan line gap
    // HDL-64: 8 scan line gap
    int maxScanIdStep = this->NLasers / 8;
    double minDist2 = 4.0 * this->MaxDistBetweenTwoFrames;
    double minDist3 = 4.0 * this->MaxDistBetweenTwoFrames;

    // now find the second closest point that belong to an other
    // scan line. The keypoints are sorted using scan id.
    for (int pointIndex = closestPointIndex + 1; pointIndex < this->PreviousPlanarsPoints->size(); ++pointIndex)
    {
      if (pointIndex > this->PreviousEdgesPoints->size() - 1)
      {
        break;
      }

      Point candidate = this->PreviousPlanarsPoints->points[pointIndex];
      bool isSameScan = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) > iD + maxScanIdStep;

      if (shouldBreak)
      {
        break;
      }

      // compute the distance
      double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);
      if (isSameScan)
      {
        if (dist < minDist2)
        {
          minDist2 = dist;
          secondPointIndex = pointIndex;
        }
      }
      else
      {
        if (dist < minDist3)
        {
          minDist3 = dist;
          thirdPointIndex = pointIndex;
        }
      }
    }
    // left side
    for (int pointIndex = closestPointIndex - 1; pointIndex >= 0; --pointIndex)
    {
      if (pointIndex < 0)
      {
        break;
      }

      Point candidate = this->PreviousPlanarsPoints->points[pointIndex];
      bool isSameScan = (static_cast<int>(candidate.normal_y) == iD);
      bool shouldBreak = static_cast<int>(candidate.normal_y) < iD - maxScanIdStep;

      if (shouldBreak)
      {
        break;
      }

      // compute the distance
      double dist = (p.x - candidate.x) * (p.x - candidate.x) + (p.y - candidate.y) * (p.y - candidate.y) + (p.z - candidate.z) * (p.z - candidate.z);
      if (isSameScan)
      {
        if (dist < minDist2)
        {
          minDist2 = dist;
          secondPointIndex = pointIndex;
        }
      }
      else
      {
        if (dist < minDist3)
        {
          minDist3 = dist;
          thirdPointIndex = pointIndex;
        }
      }
    }
  }

  matchPlaneIndex1[currentPlaneIndex] = closestPointIndex;
  matchPlaneIndex2[currentPlaneIndex] = secondPointIndex;
  matchPlaneIndex3[currentPlaneIndex] = thirdPointIndex;
  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeLineDistanceParameters(std::vector<int>& matchEdgeIndex1, std::vector<int>& matchEdgeIndex2, unsigned int edgeIndex)
{
  Point p, p1, p2;
  Eigen::Matrix<double, 3, 1> P1, P2, n, X;
  Eigen::Matrix<double, 3, 3> A;
  
  // if the current keypoint has not corresponding line match
  if ((matchEdgeIndex1[edgeIndex] == -1) || (matchEdgeIndex2[edgeIndex] == -1))
  {
    return;
  }

  p = this->CurrentEdgesPoints->points[edgeIndex];
  p1 = this->PreviousEdgesPoints->points[matchEdgeIndex1[edgeIndex]];
  p2 = this->PreviousEdgesPoints->points[matchEdgeIndex2[edgeIndex]];
  X << p.x, p.y, p.z;
  P1 << p1.x, p1.y, p1.z;
  P2 << p2.x, p2.y, p2.z;

  // n is the director vector of the line
  n = (P2 - P1).normalized();

  // A = (I-n*n.t).t * (I-n*n.t) = (I - n*n.t)^2
  // since (I-n*n.t) is a symmetric matrix.
  A = (this->I3 - n * n.transpose());
  A = A.transpose() * A;

  // it would be the case if P1 = P2 For instance
  // if the sensor has some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(P1);
  this->Xvalues.push_back(X);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputePlaneDistanceParameters(std::vector<int>& matchPlaneIndex1, std::vector<int>& matchPlaneIndex2, std::vector<int>& matchPlaneIndex3, unsigned int planarIndex)
{
  Point p, p1, p2, p3;
  Eigen::Matrix<double, 3, 1> P1, P2, P3, n, X;
  Eigen::Matrix<double, 3, 3> A;
  
  // if the current keypoint has not corresponding
  // plane match
  if ((matchPlaneIndex1[planarIndex] == -1) || (matchPlaneIndex2[planarIndex] == -1) || (matchPlaneIndex3[planarIndex] == -1))
  {
    return;
  }

  if (matchPlaneIndex1[planarIndex] < 0 || matchPlaneIndex2[planarIndex] < 0 || matchPlaneIndex3[planarIndex] < 0)
  {
    return;
  }
  if (matchPlaneIndex1[planarIndex] >= this->PreviousPlanarsPoints->size() ||
      matchPlaneIndex2[planarIndex] >= this->PreviousPlanarsPoints->size() ||
      matchPlaneIndex3[planarIndex] >= this->PreviousPlanarsPoints->size())
  {
    return;
  }

  p = this->CurrentPlanarsPoints->points[planarIndex];
  p1 = this->PreviousPlanarsPoints->points[matchPlaneIndex1[planarIndex]];
  p2 = this->PreviousPlanarsPoints->points[matchPlaneIndex2[planarIndex]];
  p3 = this->PreviousPlanarsPoints->points[matchPlaneIndex3[planarIndex]];
  X << p.x, p.y, p.z;
  P1 << p1.x, p1.y, p1.z;
  P2 << p2.x, p2.y, p2.z;
  P3 << p3.x, p3.y, p3.z;

  // n is the director vector of the line
  n = ((P3 - P1).cross(P2 - P1)).normalized();

  // A = n*n.t
  A = n * n.transpose();

  // it would be the case if P1 = P2, P1 = P3
  // or P3 = P2. For instance if the sensor has
  // some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(P1);
  this->Xvalues.push_back(X);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeLineDistanceParametersAccurate(pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges, Eigen::Matrix<double, 3, 3>& R,
                                                    Eigen::Matrix<double, 3, 1>& dT, Point p, std::string step)
{
  // number of neighbors edge points required to approximate
  // the corresponding egde line
  unsigned int requiredNearest;
  unsigned int eigenValuesRatio;

  // maximum distance between keypoints
  // and their computed line
  double maxDist;

  if (step == "egoMotion")
  {
    requiredNearest = this->EgoMotionLineDistanceNbrNeighbors;
    eigenValuesRatio = this->EgoMotionLineDistancefactor;
    maxDist = std::pow(this->EgoMotionMaxLineDistance, 2);
  }
  else if (step == "mapping")
  {
    requiredNearest = this->MappingLineDistanceNbrNeighbors;
    eigenValuesRatio = this->MappingLineDistancefactor;
    maxDist = std::pow(this->MappingMaxLineDistance, 2);
  }
  else
  {
    throw "ComputeLineDistanceParametersAccurate function got invalide step parameter";
  }

  Eigen::Matrix<double, 3, 1> P0, P, n;
  Eigen::Matrix<double, 3, 3> A;

  // Transform the point using the current pose estimation
  P << p.x, p.y, p.z;
  P0 = P;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);
  
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;

  if (step == "egoMotion")
  {
    GetEgoMotionLineSpecificNeighbor(nearestIndex, nearestDist, requiredNearest, kdtreePreviousEdges, p);
    if (nearestIndex.size() < this->EgoMotionMinimumLineNeighborRejection)
    {
      return;
    }
    requiredNearest = nearestIndex.size();
  }
  else if (step == "mapping")
  {
    GetMappingLineSpecificNeigbbor(nearestIndex, nearestDist, this->MappingLineMaxDistInlier, requiredNearest, kdtreePreviousEdges, p);
    if (nearestIndex.size() < this->MappingMinimumLineNeighborRejection)
    {
      return;
    }
    requiredNearest = nearestIndex.size();
    //kdtreePreviousEdges->nearestKSearch(p, requiredNearest, nearestIndex, nearestDist);
  }

  // if the nearest edges are too far from the
  // current edge keypoint we skip this point.
  if (nearestDist[requiredNearest - 1] > this->MaxDistanceForICPMatching)
  {
    return;
  }

  // Compute PCA to determine best line approximation
  // of the requiredNearest nearest edges points extracted
  // Thans to the PCA we will check the shape of the neighborhood
  // and keep it if it is distributed along a line
  Eigen::MatrixXd data(requiredNearest, 3);

  for (unsigned int k = 0; k < requiredNearest; k++)
  {
    Point pt = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[k]];
    data.row(k) << pt.x, pt.y, pt.z;
  }

  Eigen::Matrix<double, 3, 1> mean = data.colwise().mean();
  Eigen::MatrixXd centered = data.rowwise() - mean.transpose();
  Eigen::MatrixXd cov = centered.transpose() * centered;
  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> eig(cov);

  // Eigen values
  Eigen::MatrixXd D(1,3);
  // Eigen vectors
  Eigen::MatrixXd V(3,3);

  D = eig.eigenvalues();
  V = eig.eigenvectors();

  // if the first eigen value is significantly higher than
  // the second one, it means the sourrounding points are 
  // distributed on a edge line
  if (D(2) > eigenValuesRatio * D(1))
  {
    // n is the director vector of the line
    n = V.col(2);
    n.normalized();
  }
  else
  {
    return;
  }

  // A = (I-n*n.t).t * (I-n*n.t) = (I - n*n.t)^2
  // since (I-n*n.t) is a symmetric matrix.
  A = (this->I3 - n * n.transpose());
  A = A.transpose() * A;

  // it would be the case if P1 = P2 For instance
  // if the sensor has some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  Eigen::Matrix<double, 3, 1> Xtemp;
  Point pt;
  for (unsigned int k = 0; k < requiredNearest; ++k)
  {
    pt = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[k]];
    Xtemp(0) = pt.x;
    Xtemp(1) = pt.y;
    Xtemp(2) = pt.z;
    if ( ((Xtemp - mean).transpose() * A * (Xtemp - mean)) > maxDist )
    {
      return;
    }
  }

  // distance between current point and the corresponding matching line
  double s = 1.0;
  if (step == "mapping")
  {
    s = 1 - 0.9 * std::sqrt((P - mean).transpose() * A * (P - mean));
    if (s < 0.1)
    {
      return;
    }
  }

  else if (step == "egoMotion")
  {
    // Score the point - line matching by the angle of the
    // line with ez. The idea is that the lidar is more accurate
    // in line detection when those lines are colinear with the
    // azimutal rotation axis.
    s = 0.5 + 0.5 * n(2) * n(2); // score the match by its angle with ez
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(mean);
  this->Xvalues.push_back(P0);
  this->OutlierDistScale.push_back(s);
  this->RadiusIncertitude.push_back(0.0);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputePlaneDistanceParametersAccurate(pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousPlanes, Eigen::Matrix<double, 3, 3>& R,
                                                     Eigen::Matrix<double, 3, 1>& dT, Point p, std::string step)
{
  // number of neighbors edge points required to approximate
  // the corresponding egde line
  unsigned int requiredNearest;
  unsigned int significantlyFactor1, significantlyFactor2;

  // maximum distance between keypoints
  // and their computed plane
  double maxDist;

  if (step == "egoMotion")
  {
    significantlyFactor1 = this->EgoMotionPlaneDistancefactor1;
    significantlyFactor2 = this->EgoMotionPlaneDistancefactor2;
    requiredNearest = this->EgoMotionPlaneDistanceNbrNeighbors;
    maxDist = std::pow(this->EgoMotionMaxPlaneDistance, 2);
  }
  else if (step == "mapping")
  {
    significantlyFactor1 = this->MappingPlaneDistancefactor1;
    significantlyFactor2 = this->MappingPlaneDistancefactor2;
    requiredNearest = this->MappingPlaneDistanceNbrNeighbors;
    maxDist = std::pow(this->MappingMaxPlaneDistance, 2);
  }
  else
  {
    throw "ComputeLineDistanceParametersAccurate function got invalide step parameter";
  }

  Eigen::Matrix<double, 3, 1> P0, P, n;
  Eigen::Matrix<double, 3, 3> A;

  // Transform the point using the current pose estimation
  P << p.x, p.y, p.z;
  P0 = P;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);
  
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  kdtreePreviousPlanes->nearestKSearch(p, requiredNearest, nearestIndex, nearestDist);

  // It means that there is not enought keypoints in the neighbohood
  if (nearestIndex.size() < requiredNearest)
  {
    return;
  }

  // if the nearest planars are too far from the
  // current planar keypoint we skip this point.
  if (nearestDist[requiredNearest - 1] > this->MaxDistanceForICPMatching)
  {
    return;
  }

  // Compute PCA to determine best line approximation
  // of the requiredNearest nearest edges points extracted
  // Thanks to the PCA we will check the shape of the neighborhood
  // and keep it if it is distributed along a line
  Eigen::MatrixXd data(requiredNearest,3);

  for (unsigned int k = 0; k < requiredNearest; k++)
  {
    Point pt = kdtreePreviousPlanes->getInputCloud()->points[nearestIndex[k]];
    data.row(k) << pt.x, pt.y, pt.z;
  }

  Eigen::Matrix<double, 3, 1> mean = data.colwise().mean();
  Eigen::MatrixXd centered = data.rowwise() - mean.transpose();
  Eigen::MatrixXd cov = centered.transpose() * centered;
  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> eig(cov);

  // Eigen values
  Eigen::MatrixXd D(1,3);
  // Eigen vectors
  Eigen::MatrixXd V(3,3);

  D = eig.eigenvalues();
  V = eig.eigenvectors();

  // if the second eigen value is close to the highest one
  // and bigger than the smallest one it means that the points
  // are distributed among a plane
  Eigen::Matrix<double, 3, 1> u, v;
  if ( (significantlyFactor2 * D(1) > D(2)) && (D(1) > significantlyFactor1 * D(0)) )
  {
    u = V.col(2);
    v = V.col(1);
  }
  else
  {
    return;
  }

  n = u.cross(v);
  n.normalized();

  // A = n*n.t
  A = n * n.transpose();

  // it would be the case if P1 = P2, P1 = P3
  // or P3 = P2. For instance if the sensor has
  // some dual returns that hit the same point
  if (!vtkMath::IsFinite(A(0, 0)))
  {
    return;
  }

  Eigen::Matrix<double, 3, 1> Xtemp;
  Point pt;
  for (unsigned int k = 0; k < requiredNearest; ++k)
  {
    pt = kdtreePreviousPlanes->getInputCloud()->points[nearestIndex[k]];
    Xtemp(0) = pt.x;
    Xtemp(1) = pt.y;
    Xtemp(2) = pt.z;
    if ( ((Xtemp - mean).transpose() * A * (Xtemp - mean)) > maxDist )
    {
      return;
    }
  }

  // distance between current point and the corresponding matching plane
  double s = 1.0;
  if (step == "mapping")
  {
    s = 1 - 0.9 * std::sqrt((P - mean).transpose() * A * (P - mean)) / std::sqrt(P.norm());
    if (s < 0.1)
    {
      return;
    }
  }

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(mean);
  this->Xvalues.push_back(P0);
  this->OutlierDistScale.push_back(s);
  this->RadiusIncertitude.push_back(0.0);
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeBlobsDistanceParametersAccurate(pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousBlobs, Eigen::Matrix<double, 3, 3>& R,
                                            Eigen::Matrix<double, 3, 1>& dT, Point p, std::string step)
{
  // number of neighbors blobs points required to approximate
  // the corresponding ellipsoide
  unsigned int requiredNearest;

  // maximum distance between keypoints
  // and its neighbor
  double maxDist;

  if (step == "egoMotion")
  {
    requiredNearest = 5;
    maxDist = 6.5;
  }
  else if (step == "mapping")
  {
    requiredNearest = 7;
    maxDist = 5.0;
  }
  else
  {
    throw "ComputeLineDistanceParametersAccurate function got invalide step parameter";
  }

  // Usefull variables
  Eigen::Matrix<double, 3, 1> P0, P, n;
  Eigen::Matrix<double, 3, 3> A;

  // Transform the point using the current pose estimation
  P << p.x, p.y, p.z;
  P0 = P;
  P = R * P + dT;
  p.x = P(0); p.y = P(1); p.z = P(2);

  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  kdtreePreviousBlobs->nearestKSearch(p, requiredNearest, nearestIndex, nearestDist);

  // It means that there is not enought keypoints in the neighbohood
  if (nearestIndex.size() < requiredNearest)
  {
    return;
  }

  // if the nearest blobs is too far from the
  // current blob keypoint we skip this point.
  if (nearestDist[requiredNearest - 1] > maxDist)
  {
    return;
  }

  // Compute PCA to determine best ellipsoide approximation
  // of the requiredNearest nearest blobs points extracted
  // Thanks to the PCA we will check the shape of the neighborhood
  // tune a distance function adapter to the distribution
  // (Mahalanobis distance)
  Eigen::MatrixXd data(requiredNearest, 3);

  for (unsigned int k = 0; k < requiredNearest; k++)
  {
    Point pt = kdtreePreviousBlobs->getInputCloud()->points[nearestIndex[k]];
    data.row(k) << pt.x, pt.y, pt.z;
  }

  Eigen::Matrix<double, 3, 1> mean = data.colwise().mean();
  Eigen::MatrixXd centered = data.rowwise() - mean.transpose();
  Eigen::MatrixXd cov = centered.transpose() * centered;

  // Sigma is the inverse of the covariance
  // Matrix encoding the mahalanobis distance
  if (std::abs(cov.determinant()) < 1e-6)
  {
    return;
  }
  Eigen::MatrixXd sigma = cov.inverse();
  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> eig(sigma);

  // rescale the variance covariance matrix to preserve the
  // shape of the mahalanobis distance but removing the
  // variance values scaling
  Eigen::MatrixXd D = eig.eigenvalues();
  Eigen::MatrixXd U = eig.eigenvectors();
  D = D / D(2);
  Eigen::Matrix<double, 3, 3> diagD = Eigen::Matrix<double, 3, 3>::Zero();
  diagD(0, 0) = D(0); diagD(1, 1) = D(1); diagD(2, 2) = D(2);
  A = U * diagD * U.transpose();

  if (!vtkMath::IsFinite(A.determinant()))
  {
    return;
  }

  // Coefficient the distance
  // using the distance between the point
  // and its matching blob; The aim is to prevent
  // wrong matching to pull the point cloud in the
  // bad direction
  double s = 1.0;//1.0 - nearestDist[requiredNearest - 1] / maxDist;

  // store the distance parameters values
  this->Avalues.push_back(A);
  this->Pvalues.push_back(mean);
  this->Xvalues.push_back(P0);
  this->OutlierDistScale.push_back(s);
  this->RadiusIncertitude.push_back(0.0);
}

//-----------------------------------------------------------------------------
void vtkSlam::GetEgoMotionLineSpecificNeighbor(std::vector<int>& nearestValid, std::vector<float>& nearestValidDist,
                                               unsigned int nearestSearch, pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges, Point p)
{
  // clear vector
  nearestValid.clear();
  nearestValid.resize(0);
  nearestValidDist.clear();
  nearestValidDist.resize(0);

  // get nearest neighbor of the query point
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  kdtreePreviousEdges->nearestKSearch(p, nearestSearch, nearestIndex, nearestDist);

  // take the closest point
  std::vector<int> idAlreadyTook(this->NLasers, 0);
  Point closest = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[0]];
  nearestValid.push_back(nearestIndex[0]);
  nearestValidDist.push_back(nearestDist[0]);

  // invalid all possible points that
  // are on the same scan line than the
  // closest one
  idAlreadyTook[(int)closest.normal_y] = 1;

  // invalid all possible points from scan
  // lines that are too far from the closest one
  for (int k = 0; k < this->NLasers; ++k)
  {
    if (std::abs(closest.normal_y - k) > 3)
    {
      idAlreadyTook[k] = 1;
    }
  }

  // Make a selection among the neighborhood
  // of the query point. We can only take one edge
  // per scan line
  int id;
  for (unsigned int k = 1; k < nearestIndex.size(); ++k)
  {
    id = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[k]].normal_y;
    if (idAlreadyTook[id] < 1)
    {
      idAlreadyTook[id] = 1;
      nearestValid.push_back(nearestIndex[k]);
      nearestValidDist.push_back(nearestDist[k]);
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::GetEgoMotionPlaneSpecificNeighbor()
{

}

//-----------------------------------------------------------------------------
void vtkSlam::GetMappingLineSpecificNeigbbor(std::vector<int>& nearestValid, std::vector<float>& nearestValidDist, double maxDistInlier,
                                             unsigned int nearestSearch, pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges, Point p)
{
  // reset vectors
  nearestValid.clear();
  nearestValid.resize(0);
  nearestValidDist.clear();
  nearestValidDist.resize(0);

  // to prevent square root when making camparisons
  maxDistInlier = std::pow(maxDistInlier, 2);

  // Take the neighborhood of the query point
  // get nearest neighbor of the query point
  std::vector<int> nearestIndex;
  std::vector<float> nearestDist;
  kdtreePreviousEdges->nearestKSearch(p, nearestSearch, nearestIndex, nearestDist);

  // take the closest point
  std::vector<std::vector<int> > inliersList;
  Point closest = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[0]];
  nearestValid.push_back(nearestIndex[0]);
  nearestValidDist.push_back(nearestDist[0]);

  Eigen::Matrix<double, 3, 1> P1, P2, dir, Pcdt;
  Eigen::Matrix<double, 3, 3> D;
  P1 << closest.x, closest.y, closest.z;
  Point pclP2;
  Point inlierCandidate;

  // Loop over other neighbors of the neighborhood. For each of them
  // compute the line between closest point and current point and
  // compute the number of inlier that fit this line. Keep the line and its
  // inmliers with the most inliers
  for (unsigned int ptIndex = 1; ptIndex < nearestIndex.size(); ++ptIndex)
  {
    std::vector<int> inlierIndex;
    pclP2 = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[ptIndex]];
    P2 << pclP2.x, pclP2.y, pclP2.z;
    dir = (P2 - P1).normalized();
    D = this->I3 - dir * dir.transpose();
    D = D.transpose() * D;

    for (unsigned int candidateIndex = 1; candidateIndex < nearestIndex.size(); ++candidateIndex)
    {
      inlierCandidate = kdtreePreviousEdges->getInputCloud()->points[nearestIndex[candidateIndex]];
      Pcdt << inlierCandidate.x, inlierCandidate.y, inlierCandidate.z;
      if ( (Pcdt - P1).transpose() * D * (Pcdt - P1) < maxDistInlier)
      {
        inlierIndex.push_back(candidateIndex);
      }
    }
    inliersList.push_back(inlierIndex);
  }

  int maxInliers = 0;
  int indexMaxInliers = -1;
  for (unsigned int k = 0; k < inliersList.size(); ++k)
  {
    if (inliersList[k].size() > maxInliers)
    {
      maxInliers = inliersList[k].size();
      indexMaxInliers = k;
    }
  }

  // fill
  for (unsigned int k = 0; k < inliersList[indexMaxInliers].size(); ++k)
  {
    nearestValid.push_back(nearestIndex[inliersList[indexMaxInliers][k]]);
    nearestValidDist.push_back(nearestDist[inliersList[indexMaxInliers][k]]);
  }

  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::GetMappingPlaneSpecificNeigbbor()
{

}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeResidualValues(std::vector<Eigen::Matrix<double, 3, 3> >& vA, std::vector<Eigen::Matrix<double, 3, 1> >& vX,
                                    std::vector<Eigen::Matrix<double, 3, 1> >& vP, std::vector<double>& vS,
                                    Eigen::Matrix<double, 3, 3>& R, Eigen::Matrix<double, 3, 1>& dT, Eigen::MatrixXd& residuals)
{
  residuals = Eigen::MatrixXd(vX.size(), 1);
  Eigen::Matrix<double, 3, 1> Xp;
  double s;
  for (unsigned int k = 0; k < vX.size(); ++k)
  {
    s = vS[k];
    Xp = R * vX[k] + dT;
    residuals(k) = std::max(std::sqrt(std::abs((Xp - vP[k]).transpose() * vA[k] * (Xp - vP[k]))) - this->RadiusIncertitude[k], 0.0);
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeResidualJacobians(std::vector<Eigen::Matrix<double, 3, 3> >& vA, std::vector<Eigen::Matrix<double, 3, 1> >& vX,
                                       std::vector<Eigen::Matrix<double, 3, 1> >& vP, std::vector<double> vS,
                                       Eigen::Matrix<double, 6, 1>& T, Eigen::MatrixXd& residualsJacobians)
{
  residualsJacobians = Eigen::MatrixXd(vX.size(), 6);

  bool warned = false;
  double epsilon = 1e-5;
  double rx, ry, rz;
  rx = T(0); ry = T(1); rz = T(2);
  double X1, X2, X3;
  double C1, C2, C3;
  Eigen::Matrix<double, 3, 3> A;
  Eigen::Matrix<double, 3, 3> R = GetRotationMatrix(T);
  Eigen::Matrix<double, 3, 1> dT;
  dT << T(3), T(4), T(5);

  // cosinus and sinus of the current
  // estimated angles for the ego-motion
  // This is done in order to speed the algortihm
  // full rotation
  double crx, srx;
  double cry, sry;
  double crz, srz;
  crx = std::cos(rx); srx = std::sin(rx);
  cry = std::cos(ry); sry = std::sin(ry);
  crz = std::cos(rz); srz = std::sin(rz);

  // scale factor for outliers points
  // so that they do not have big influence
  // on the final result (whereas pure square
  // distance would give outlier points a too big
  // influence on the final result)
  double s;

  for (unsigned int k = 0; k < vX.size(); ++k)
  {
    // here the cost funtion is the distance between
    // the current plane/ edge point and its corresponding line / plane.
    // The distance is f(R,T)=sqrt((R*X+T - P).t * A * (R*X+T - P))
    // To compute the jacobian we will use the chain-rule
    // we define g(X) = sqrt(X.t * A * X) and h(R,T)=R*X+T-P1
    // Hence, f(R,T) = g(h(R, T)) and the jacobian
    // Jf(R,T) = Jg(h(R,T))*Jh(R,T)
    s = vS[k];
    X1 = vX[k](0); X2 = vX[k](1); X3 = vX[k](2);
    C1 = vP[k](0); C2 = vP[k](1); C3 = vP[k](2);
    A = vA[k];

    // represents h(R,T)
    Eigen::Matrix<double, 3, 1> h_R_t = R * vX[k] + dT - vP[k];

    // represent the jacobian of the G function
    // evaluated at the point h(R,T). Note that G is
    // the composition of the functions sqrt and X' * A * X
    // and is not differentiable when X'*A*X = 0
    Eigen::Matrix<double, 1, 3> JacobianG;
    double dist = std::sqrt(h_R_t.transpose() * A * h_R_t);

    if (dist - this->RadiusIncertitude[k] < 0)
    {
      for (unsigned int i = 0; i < 6; ++i)
      {
        residualsJacobians(k, i) = 0.0;
      }
      continue;
    }

    if (dist > 1e-12)
    {
      JacobianG = 1.0 / (2.0 * dist) * s * s * h_R_t.transpose() * (A + A.transpose());
    }

    // represent the jacobian of the H function
    // evaluated at the point R, T
    Eigen::Matrix<double, 3, 6> JacobianH;
    // dx / drx
    JacobianH(0, 0) = (srz * srx + crz * sry * crx) * X2 + (srz * crx - crz * sry * srx) * X3;
    // dx / dry
    JacobianH(0, 1) = -crz * sry * X1 + crz * cry * srx * X2 + crz * cry * crx * X3;
    // dx / drz
    JacobianH(0, 2) = -srz * cry * X1 + (-crz * crx - srz * sry * srx) * X2+ (crz * srx - srz * sry * crx) * X3;
    // dx / dtx
    JacobianH(0, 3) = 1;
    // dx / dty
    JacobianH(0, 4) = 0;
    // dx / dtz
    JacobianH(0, 5) = 0;
    // dy / drx
    JacobianH(1, 0) = (-crz * srx + srz * sry * crx) * X2 + (-crz * crx - srz * sry * srx) * X3;
    // dy / dry
    JacobianH(1, 1) = -srz * sry * X1 + srz * cry * srx * X2 + srz * cry * crx * X3;
    // dy / drz
    JacobianH(1, 2) = crz * cry * X1 + (-srz * crx + crz * sry * srx) * X2 + (srz * srx + crz * sry * crx) * X3;
    // dy / dtx
    JacobianH(1, 3) = 0;
    // dy / dty
    JacobianH(1, 4) = 1;
    // dy / dtz
    JacobianH(1, 5) = 0;
    // dz / drx
    JacobianH(2, 0) = cry * crx * X2 - cry * srx * X3;
    // dz / dry
    JacobianH(2, 1) = -cry * X1 - sry * srx * X2 - sry * crx * X3;
    // dz / drz
    JacobianH(2, 2) = 0;
    // dz / dtx
    JacobianH(2, 3) = 0;
    // dz / dty
    JacobianH(2, 4) = 0;
    // dr / dtz
    JacobianH(2, 5) = 1;

    Eigen::Matrix<double, 1, 6> currentJacobian = JacobianG * JacobianH;

    for (unsigned int i = 0; i < 6; ++i)
    {
      residualsJacobians(k, i) = currentJacobian(0, i);
    }
  }
}

//-----------------------------------------------------------------------------
void vtkSlam::ComputeEgoMotion()
{
  // Check that there is enought points to compute the EgoMotion
  if ((this->CurrentEdgesPoints->size() == 0 || this->PreviousEdgesPoints->size() == 0) &&
      (this->CurrentPlanarsPoints->size() == 0 || this->PreviousPlanarsPoints->size() == 0))
  {
    this->FillEgoMotionInfoArrayWithDefaultValues();
    vtkGenericWarningMacro("Not enought keypoints, EgoMotion skipped for this frame");
    return;
  }

  // reset the relative transform
  this->Trelative = Eigen::Matrix<double, 6, 1>::Zero();

  // kd-tree to process fast nearest neighbor
  // among the keypoints of the previous pointcloud
  pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousEdges(new pcl::KdTreeFLANN<Point>());
  pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousPlanes(new pcl::KdTreeFLANN<Point>());
  pcl::KdTreeFLANN<Point>::Ptr kdtreePreviousBlobs(new pcl::KdTreeFLANN<Point>());
  kdtreePreviousEdges->setInputCloud(this->PreviousEdgesPoints);
  kdtreePreviousPlanes->setInputCloud(this->PreviousPlanarsPoints);
  kdtreePreviousBlobs->setInputCloud(this->PreviousBlobsPoints);

  std::cout << "Performing ego-motion using : " << std::endl;
  std::cout << "previous edges : " << this->PreviousEdgesPoints->size() << " current edges : " << this->CurrentEdgesPoints->size() << std::endl;
  std::cout << "previous planes : " << this->PreviousPlanarsPoints->size() << " current planes : " << this->CurrentPlanarsPoints->size() << std::endl;

  unsigned int usedEdges = 0;
  unsigned int usedPlanes = 0;
  unsigned int usedBlobs = 0;
  Point currentPoint, transformedPoint;

  // ICP - Levenberg-Marquardt loop:
  // At each step of this loop an ICP matching is performed
  // Once the keypoints matched, we estimate the the 6-DOF
  // parameters by minimizing a non-linear least square cost
  // function using a Levenberg-Marquardt algorithm
  for (unsigned int icpCount = 0; icpCount < this->EgoMotionICPMaxIter; ++icpCount)
  {
    // Rotation and translation at this step
    Eigen::Matrix<double, 3, 3> R = GetRotationMatrix(this->Trelative);
    Eigen::Matrix<double, 3, 1> T;
    T << this->Trelative(3), this->Trelative(4), this->Trelative(5);

    // clear all keypoints matching data
    this->ResetDistanceParameters();

    // loop over edges
    for (unsigned int edgeIndex = 0; edgeIndex < this->CurrentEdgesPoints->size(); ++edgeIndex)
    {
      currentPoint = this->CurrentEdgesPoints->points[edgeIndex];

      // Find the closest correspondence edge line of the current edge point
      if ((this->PreviousEdgesPoints->size() > 7) && (this->CurrentEdgesPoints->size() > 0))
      {
        // Compute the parameters of the point - line distance
        // i.e A = (I - n*n.t)^2 with n being the director vector
        // and P a point of the line
        this->ComputeLineDistanceParametersAccurate(kdtreePreviousEdges, R, T, currentPoint, "egoMotion");
        usedEdges = this->Xvalues.size();
      }
    }

    // loop over surfaces
    for (unsigned int planarIndex = 0; planarIndex < this->CurrentPlanarsPoints->size(); ++planarIndex)
    {
      currentPoint = this->CurrentPlanarsPoints->points[planarIndex];

      // Find the closest correspondence plane of the current planar point
      if ((this->PreviousPlanarsPoints->size() > 7) && (this->CurrentPlanarsPoints->size() > 0))
      {
        // Compute the parameters of the point - plane distance
        // i.e A = n * n.t with n being a normal of the plane
        // and is a point of the plane
        this->ComputePlaneDistanceParametersAccurate(kdtreePreviousPlanes, R, T, currentPoint, "egoMotion");
        usedPlanes = this->Xvalues.size() - usedEdges;
      }
    }

    // loop over blobs
    if (!this->FastSlam)
    {
      for (unsigned int blobIndex = 0; blobIndex < this->CurrentBlobsPoints->size(); ++blobIndex)
      {
        currentPoint = this->CurrentBlobsPoints->points[blobIndex];

        // Find the closest correspondence blob of the current blob point
        if (this->CurrentBlobsPoints->size() > 2)
        {
          //this->ComputeBlobsDistanceParametersAccurate(kdtreePreviousBlobs, R, dT, currentPoint, "egoMotion");
          usedBlobs = this->Xvalues.size() - usedPlanes - usedEdges;
        }
      }
    }

    // Skip this frame if there is too few geometric
    // keypoints matched
    if ((usedPlanes + usedEdges + usedBlobs) < 20)
    {
      vtkGenericWarningMacro("Too few geometric features, frame skipped");
      break;
    }

    // We want to estimate our 6-DOF parameters using a non
    // linear least square minimization. The non linear part
    // comes from the Euler Angle parametrization of the rotation
    // endomorphism SO(3). To minimize it we use CERES to perform
    // the Levenberg-Marquardt algorithm.
    ceres::Problem problem;
    for (unsigned int k = 0; k < Xvalues.size(); ++k)
    {
      ceres::CostFunction* cost_function = new ceres::AutoDiffCostFunction<AffineIsometryResidual, 1, 1, 1, 1, 1, 1, 1>(
                                            new AffineIsometryResidual(this->Avalues[k], this->Pvalues[k], this->Xvalues[k]));
      problem.AddResidualBlock(cost_function, NULL, &this->Trelative(0), &this->Trelative(1), &this->Trelative(2), &this->Trelative(3), &this->Trelative(4), &this->Trelative(5));
    }

    ceres::Solver::Options options;
    options.max_num_iterations = this->EgoMotionLMMaxIter;
    options.linear_solver_type = ceres::DENSE_QR;
    options.minimizer_progress_to_stdout = false;

    ceres::Solver::Summary summary;
    ceres::Solve(options, &problem, &summary);
    std::cout << summary.BriefReport() << std::endl;

    // If no L-M iteration has been made since the
    // last ICP matching it means we reached a local
    // minimum for the ICP-LM algorithm
    if (summary.num_successful_steps == 1)
    {
      break;
    }
  }
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: intiale cost function"))->InsertNextValue(0);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: final cost function"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: edges used"))->InsertNextValue(usedEdges);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: planes used"))->InsertNextValue(usedPlanes);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: blobs used"))->InsertNextValue(usedBlobs);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: total keypoints used"))->InsertNextValue(this->Xvalues.size());
  std::cout << "used keypoints : " << this->Xvalues.size() << std::endl;
  std::cout << "edges : " << usedEdges << " planes : " << usedPlanes << " blobs : " << usedBlobs << std::endl;

  // Integrate the relative motion
  // to the world transformation
  this->UpdateTworldUsingTrelative();
}

//-----------------------------------------------------------------------------
void vtkSlam::Mapping()
{
  // Check that there is enought points to compute the EgoMotion
  if (this->CurrentEdgesPoints->size() == 0 && this->CurrentPlanarsPoints->size() == 0)
  {
    this->FillMappingInfoArrayWithDefaultValues();
    // update maps
    this->UpdateMapsUsingTworld();
    vtkGenericWarningMacro("Not enought keypoints, Mapping skipped for this frame");
    return;
  }

  // contruct kd-tree for fast search
  pcl::KdTreeFLANN<Point>::Ptr kdtreeEdges(new pcl::KdTreeFLANN<Point>());
  pcl::KdTreeFLANN<Point>::Ptr kdtreePlanes(new pcl::KdTreeFLANN<Point>());
  pcl::KdTreeFLANN<Point>::Ptr kdtreeBlobs(new pcl::KdTreeFLANN<Point>());

  // Compute the number of voxel required depending on the
  // max range of the keypoints
  // the max keypoint distance in number of voxel
  double requiredVoxels = this->FarestKeypointDist / static_cast<double>(this->EdgesPointsLocalMap->Get_VoxelSize());
  // Since we want a diameter and not the radius, multiply it by two; Add an extra 10% distance
  unsigned int nbrRequiredVoxels = static_cast<unsigned int>(vtkMath::Round(1.15 * 2.0 * requiredVoxels));
  double voxelsR[3] = {nbrRequiredVoxels, nbrRequiredVoxels, nbrRequiredVoxels};
  // Set it
  this->Set_RollingGrid_PointCloud_NbVoxel(voxelsR);

  pcl::PointCloud<Point>::Ptr subEdgesPointsLocalMap = this->EdgesPointsLocalMap->Get(this->Tworld);
  pcl::PointCloud<Point>::Ptr subPlanarPointsLocalMap = this->PlanarPointsLocalMap->Get(this->Tworld);
  pcl::PointCloud<Point>::Ptr subBlobPointsLocalMap = this->BlobsPointsLocalMap->Get(this->Tworld);
  std::cout << "Required voxels computed using max range is: " << nbrRequiredVoxels << std::endl;
  std::cout << "edges map : " << subEdgesPointsLocalMap->points.size() << std::endl;
  std::cout << "flat map : " << subPlanarPointsLocalMap->points.size() << std::endl;
  std::cout << "blobs map : " << subBlobPointsLocalMap->points.size() << std::endl;

  kdtreeEdges->setInputCloud(subEdgesPointsLocalMap);
  kdtreePlanes->setInputCloud(subPlanarPointsLocalMap);
  kdtreeBlobs->setInputCloud(subBlobPointsLocalMap);

  unsigned int usedEdges = 0;
  unsigned int usedPlanes = 0;
  unsigned int usedBlobs = 0;
  Point currentPoint;

  // Interpolator used to undistord the frames
  vtkSmartPointer<vtkVelodyneTransformInterpolator> undistortionInterp;

  // ICP - Levenberg-Marquardt loop:
  // At each step of this loop an ICP matching is performed
  // Once the keypoints matched, we estimate the the 6-DOF
  // parameters by minimizing a non-linear least square cost
  // function using a Levenberg-Marquardt algorithm
  for (int icpCount = 0; icpCount < this->MappingICPMaxIter; ++icpCount)
  {
    // clear all keypoints matching data
    this->ResetDistanceParameters();

    // Rotation and position at this step
    Eigen::Matrix<double, 3, 3> R = GetRotationMatrix(this->Tworld);
    Eigen::Matrix<double, 3, 1> T;
    T << this->Tworld(3), this->Tworld(4), this->Tworld(5);

    // Init the undistortion interpolator
    // if required
    if (this->Undistortion)
    {
      undistortionInterp = this->InitUndistortionInterpolator();
    }

    // loop over edges
    for (unsigned int edgeIndex = 0; edgeIndex < this->CurrentEdgesPoints->size(); ++edgeIndex)
    {
      currentPoint = this->CurrentEdgesPoints->points[edgeIndex];

      // If the undistortion
      if (this->Undistortion)
        this->ExpressPointInStartReferencial(currentPoint, undistortionInterp);

      if (this->CurrentEdgesPoints->size() > 0 && subEdgesPointsLocalMap->points.size() > 10)
      {
        // Find the closest correspondence edge line of the current edge point
        this->ComputeLineDistanceParametersAccurate(kdtreeEdges, R, T, currentPoint, "mapping");
        usedEdges = this->Xvalues.size();
      }
    }

    // loop over surfaces
    for (unsigned int planarIndex = 0; planarIndex < this->CurrentPlanarsPoints->size(); ++planarIndex)
    {
      currentPoint = this->CurrentPlanarsPoints->points[planarIndex];

      // If the undistortion
      if (this->Undistortion)
        this->ExpressPointInStartReferencial(currentPoint, undistortionInterp);

      if (this->CurrentPlanarsPoints->size() > 0 && subPlanarPointsLocalMap->size() > 10)
      {
        // Find the closest correspondence plane of the current planar point
        this->ComputePlaneDistanceParametersAccurate(kdtreePlanes, R, T, currentPoint, "mapping");
        usedPlanes = this->Xvalues.size() - usedEdges;
      }
    }

    if (!this->FastSlam)
    {
      // loop over blobs
      for (unsigned int blobIndex = 0; blobIndex < this->CurrentBlobsPoints->size(); ++blobIndex)
      {
        currentPoint = this->CurrentBlobsPoints->points[blobIndex];

        // Find the closest correspondence plane of the current planar point
        this->ComputeBlobsDistanceParametersAccurate(kdtreeBlobs, R, T, currentPoint, "mapping");
        usedBlobs = this->Xvalues.size() - usedPlanes - usedEdges;
      }
    }

    // Skip this frame if there is too few geometric keypoints matched
    if ((usedPlanes + usedEdges + usedBlobs) < 20)
    {
      vtkGenericWarningMacro("Too few geometric features, loop breaked");
      std::cout << "planes: " << usedPlanes << " edges: " << usedEdges << " Blobs: " << usedBlobs << std::endl;
      break;
    }

    // We want to estimate our 6-DOF parameters using a non
    // linear least square minimization. The non linear part
    // comes from the Euler Angle parametrization of the rotation
    // endomorphism SO(3). To minimize it we use CERES to perform
    // the Levenberg-Marquardt algorithm.
    ceres::Problem problem;
    for (unsigned int k = 0; k < Xvalues.size(); ++k)
    {
      ceres::CostFunction* cost_function = new ceres::AutoDiffCostFunction<AffineIsometryResidual, 1, 1, 1, 1, 1, 1, 1>(
                                            new AffineIsometryResidual(this->Avalues[k], this->Pvalues[k], this->Xvalues[k]));
      problem.AddResidualBlock(cost_function, NULL, &this->Tworld(0), &this->Tworld(1), &this->Tworld(2), &this->Tworld(3), &this->Tworld(4), &this->Tworld(5));
    }

    ceres::Solver::Options options;
    options.max_num_iterations = this->MappingLMMaxIter;
    options.linear_solver_type = ceres::DENSE_QR;
    options.minimizer_progress_to_stdout = false;

    ceres::Solver::Summary summary;
    ceres::Solve(options, &problem, &summary);
    std::cout << summary.BriefReport() << std::endl;
 
    // If no L-M iteration has been made since the
    // last ICP matching it means we reached a local
    // minimum for the ICP-LM algorithm
    if (summary.num_successful_steps == 1)
    {
      break;
    }
  }

  // Now evaluate the quality of the parameters
  // prediction using an approxiamte computation
  // of the variance covariance matrix
  // Rotation and translation at the end of the mapping
  Eigen::Matrix<double, 3, 3> R;
  Eigen::Matrix<double, 3, 1> dT;
  R = GetRotationMatrix(this->Tworld);
  dT << this->Tworld(3), this->Tworld(4), this->Tworld(5);

  // Compute residuals values mean and variance
  Eigen::MatrixXd Y;
  this->ComputeResidualValues(this->Avalues, this->Xvalues, this->Pvalues, this->OutlierDistScale, R, dT, Y);
  double residualSum = std::sqrt(0.5 / static_cast<double>(Y.rows()) * (Y.transpose() * Y)(0));
  double meanResidual = Y.sum();
  double varResidual = 0;
  for (unsigned int k = 0; k < Y.rows(); ++k)
  {
    varResidual = std::pow(Y(k) - meanResidual, 2);
  }
  varResidual /= static_cast<double>(Y.rows());

  Eigen::MatrixXd J;
  this->ComputeResidualJacobians(this->Avalues, this->Xvalues, this->Pvalues, this->OutlierDistScale, this->Tworld, J);

  Eigen::MatrixXd JtJ = J.transpose() * J;
  Eigen::MatrixXd Sigma = varResidual * JtJ.inverse();
  Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> eig(Sigma);
  Eigen::MatrixXd D = eig.eigenvalues();

  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: intiale cost function"))->InsertNextValue(0);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: final cost function"))->InsertNextValue(0);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Variance Error"))->InsertNextValue(D(5));
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: edges used"))->InsertNextValue(usedEdges);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: planes used"))->InsertNextValue(usedPlanes);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: blobs used"))->InsertNextValue(usedBlobs);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: total keypoints used"))->InsertNextValue(this->Xvalues.size());

  std::cout << "used keypoints : " << this->Xvalues.size() << std::endl;
  std::cout << "edges : " << usedEdges << " planes : " << usedPlanes << " blobs : " << usedBlobs << std::endl;
  std::cout << "Covariance matrix: " << Sigma << std::endl;
  std::cout << "Covariance Eigen values: " << D << std::endl;
  std::cout << "Maximum variance: " << D(5) << std::endl;

  if (this->MotionModel > 0)
  {
    Eigen::MatrixXd SigmaMeas(this->KalmanEstimator.GetNbrMeasure(), this->KalmanEstimator.GetNbrMeasure());
    Eigen::MatrixXd Measure(this->KalmanEstimator.GetNbrMeasure(), 1);
    // with speed measure
    if (this->KalmanEstimator.GetMode() > 0)
    {
      // Fill the matrix
      for (unsigned int i = 0; i < this->KalmanEstimator.GetNbrMeasure(); ++i)
      {
        Measure(i, 0) = 0.0;
        for (unsigned int j = 0; j < this->KalmanEstimator.GetNbrMeasure(); ++j)
        {
          SigmaMeas(i, j) = 0.0;
        }
      }
      Eigen::Matrix<double, 3, 1> V = GetVelocityForTime(this->CurrentTime, 1.5, this->ExternalMeasures);
      for (unsigned int i = 0; i < 6; ++i)
      {
        Measure(i) = this->Tworld(i);
        for (unsigned int j = 0; j < 6; ++j)
        {
          SigmaMeas(i, j) = Sigma(i, j);
        }
      }
      Measure(6) = V.norm();
      SigmaMeas(6, 6) = this->VelocityNormCov;
    }
    else
    {
      SigmaMeas = Sigma;
      Measure = this->Tworld;
    }
    this->KalmanEstimator.Prediction();
    this->KalmanEstimator.SetMeasureCovariance(SigmaMeas);
    this->KalmanEstimator.Correction(Measure);
    Eigen::Matrix<double, 12, 1> stateVector = this->KalmanEstimator.GetStateVector();

    std::cout << "Before motion model: " << this->Tworld.transpose() << std::endl;
    for (unsigned int i = 0; i < 6; ++i)
    {
      this->Tworld(i) = stateVector(i);
    }
    std::cout << "After motion model: " << this->Tworld.transpose() << std::endl;
  }
  std::cout << "End L-M loop" << std::endl;
  // Add the current computed transform to the list
  this->TworldList.push_back(this->Tworld);

  // Express all the acquired keypoints
  // in the refenrtial corresponding of
  // the sensor's referential at the time
  // t1 of the end of the current frame
  if (this->Undistortion)
  {
    this->ExpressKeypointsInEndFrameRef();
  }

  // Update the PreviousTworld data
  this->PreviousTworld = this->Tworld;

  // update maps
  this->UpdateMapsUsingTworld();
}

//-----------------------------------------------------------------------------
void vtkSlam::UpdateMapsUsingTworld()
{
  // Update EdgeMap
  pcl::PointCloud<Point>::Ptr MapEdgesPoints(new pcl::PointCloud<Point>());
  for (unsigned int i = 0; i < this->CurrentEdgesPoints->size(); ++i)
  {
    MapEdgesPoints->push_back(this->CurrentEdgesPoints->at(i));
    this->TransformToWorld(MapEdgesPoints->at(i), this->Tworld);
  }
  EdgesPointsLocalMap->Roll(this->Tworld);
  EdgesPointsLocalMap->Add(MapEdgesPoints);

  // Update PlanarMap
  pcl::PointCloud<Point>::Ptr MapPlanarsPoints(new pcl::PointCloud<Point>());
  for (unsigned int i = 0; i < this->CurrentPlanarsPoints->size(); ++i)
  {
    MapPlanarsPoints->push_back(this->CurrentPlanarsPoints->at(i));
    this->TransformToWorld(MapPlanarsPoints->at(i), this->Tworld);
  }
  PlanarPointsLocalMap->Roll(this->Tworld);
  PlanarPointsLocalMap->Add(MapPlanarsPoints);

  // Update BlobsMap
  pcl::PointCloud<Point>::Ptr MapBlobsPoints(new pcl::PointCloud<Point>());
  for (unsigned int i = 0; i < this->CurrentBlobsPoints->size(); ++i)
  {
    MapBlobsPoints->push_back(this->CurrentBlobsPoints->at(i));
    this->TransformToWorld(MapBlobsPoints->at(i), this->Tworld);
  }
  BlobsPointsLocalMap->Roll(this->Tworld);
  BlobsPointsLocalMap->Add(MapBlobsPoints);
}

//-----------------------------------------------------------------------------
void vtkSlam::FillMappingInfoArrayWithDefaultValues()
{
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: intiale cost function"))->InsertNextValue(0.0);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: final cost function"))->InsertNextValue(10.0);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("Variance Error"))->InsertNextValue(10.0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: edges used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: planes used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: blobs used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("Mapping: total keypoints used"))->InsertNextValue(0);
}

//-----------------------------------------------------------------------------
void vtkSlam::FillEgoMotionInfoArrayWithDefaultValues()
{
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: intiale cost function"))->InsertNextValue(10.0);
  static_cast<vtkDoubleArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: final cost function"))->InsertNextValue(10.0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: edges used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: planes used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: blobs used"))->InsertNextValue(0);
  static_cast<vtkIntArray*>(this->Trajectory->GetPointData()->GetArray("EgoMotion: total keypoints used"))->InsertNextValue(0);
}

//-----------------------------------------------------------------------------
void vtkSlam::ExpressKeypointsInEndFrameRef()
{
  vtkSmartPointer<vtkVelodyneTransformInterpolator> undistordInterp = vtkSmartPointer<vtkVelodyneTransformInterpolator>::New();
  undistordInterp->SetInterpolationTypeToLinear();

  // Transforms representing the passage from the
  // referential of the sensor at time t0 resp t1
  // to the referential of the sensor at the time 0
  vtkNew<vtkTransform> transform0, transform1;

  // transform 0 is identity
  transform0->Identity();
  transform0->Modified();
  transform0->Update();

  // transform 1 is the delta transform
  // between T1 and T0
  Eigen::Matrix<double, 3, 3> R0, R1, dR;
  R0 = GetRotationMatrix(this->PreviousTworld);
  R1 = GetRotationMatrix(this->Tworld);
  dR = R1.transpose() * R0;

  Eigen::Matrix<double, 3, 1> dT;
  dT << -this->Tworld(3) + this->PreviousTworld(3),
        -this->Tworld(4) + this->PreviousTworld(4),
        -this->Tworld(5) + this->PreviousTworld(5);
  dT = R1.transpose() * dT;

  vtkNew<vtkMatrix4x4> M;
  for (unsigned int i = 0; i < 3; ++i)
  {
    for (unsigned int j = 0; j < 3; ++j)
    {
      M->Element[i][j] = dR(i, j);
    }
    M->Element[i][3] = dT(i);
    M->Element[3][i] = 0;
  }
  M->Element[3][3] = 1.0;
  transform1->SetMatrix(M.Get());
  transform1->Modified();
  transform1->Update();

  // Add the transforms and update
  undistordInterp->AddTransform(1.0, transform0.GetPointer());
  undistordInterp->AddTransform(0.0, transform1.GetPointer());
  undistordInterp->Modified();

  Point currentPoint;
  // transform points
  // Edges
  for (unsigned int k = 0; k < this->CurrentEdgesPoints->size(); ++k)
  {
    currentPoint = this->CurrentEdgesPoints->points[k];
    this->ExpressPointInEndReferencial(currentPoint, undistordInterp);
    this->CurrentEdgesPoints->points[k] = currentPoint;
  }

  // Planes
  for (unsigned int k = 0; k < this->CurrentPlanarsPoints->size(); ++k)
  {
    currentPoint = this->CurrentPlanarsPoints->points[k];
    this->ExpressPointInEndReferencial(currentPoint, undistordInterp);
    this->CurrentPlanarsPoints->points[k] = currentPoint;
  }

  // Blobs
  for (unsigned int k = 0; k < this->CurrentBlobsPoints->size(); ++k)
  {
    currentPoint = this->CurrentBlobsPoints->points[k];
    this->ExpressPointInEndReferencial(currentPoint, undistordInterp);
    this->CurrentBlobsPoints->points[k] = currentPoint;
  }
}

//-----------------------------------------------------------------------------
vtkSmartPointer<vtkVelodyneTransformInterpolator> vtkSlam::InitUndistortionInterpolator()
{
  vtkSmartPointer<vtkVelodyneTransformInterpolator> resultInterp = vtkSmartPointer<vtkVelodyneTransformInterpolator>::New();
  resultInterp->SetInterpolationTypeToLinear();

  // Transforms representing the passage from the
  // referential of the sensor at time t0 resp t1
  // to the referential of the sensor at the time 0
  vtkNew<vtkTransform> transform0, transform1;

  // transform 0 is identity
  transform0->Identity();
  transform0->Modified();
  transform0->Update();

  // transform 1 is the delta transform
  // between T0 and T1
  Eigen::Matrix<double, 3, 3> R0, R1, dR;
  R0 = GetRotationMatrix(this->PreviousTworld);
  R1 = GetRotationMatrix(this->Tworld);
  dR = R1.transpose() * R0;

  Eigen::Matrix<double, 3, 1> dT;
  dT << -this->Tworld(3) + this->PreviousTworld(3),
        -this->Tworld(4) + this->PreviousTworld(4),
        -this->Tworld(5) + this->PreviousTworld(5);
  dT = R1.transpose() * dT;

  vtkNew<vtkMatrix4x4> M;
  for (unsigned int i = 0; i < 3; ++i)
  {
    for (unsigned int j = 0; j < 3; ++j)
    {
      M->Element[i][j] = dR(i, j);
    }
    M->Element[i][3] = dT(i);
    M->Element[3][i] = 0;
  }
  M->Element[3][3] = 1.0;

  std::cout << "Delta M: " << std::endl;
  for (unsigned int i = 0; i < 4; ++i)
  {
    for (unsigned int j = 0; j < 4; ++j)
    {
      std::cout << M->Element[i][j] << ", ";
    }
    std::cout << std::endl;
  }
  std::cout << std::endl;

  transform1->SetMatrix(M.Get());
  transform1->Modified();
  transform1->Update();

  // Add the transforms and update
  resultInterp->AddTransform(1.0, transform0.GetPointer());
  resultInterp->AddTransform(0.0, transform1.GetPointer());
  resultInterp->Modified();

  return resultInterp;
}

//-----------------------------------------------------------------------------
void vtkSlam::ExpressPointInStartReferencial(Point& p, vtkSmartPointer<vtkVelodyneTransformInterpolator> undistortionInterp)
{
  // interpolate the transform
  vtkNew<vtkTransform> currTransform;
  undistortionInterp->InterpolateTransform(p.intensity, currTransform.GetPointer());
  currTransform->Modified();
  currTransform->Update();

  double pos[3] = {p.x, p.y, p.z};
  currTransform->InternalTransformPoint(pos, pos);
  p.x = pos[0];
  p.y = pos[1];
  p.z = pos[2];
}

//-----------------------------------------------------------------------------
void vtkSlam::ExpressPointInEndReferencial(Point& p, vtkSmartPointer<vtkVelodyneTransformInterpolator> undistortionInterp)
{
  // interpolate the transform
  vtkNew<vtkTransform> currTransform;
  undistortionInterp->InterpolateTransform(p.intensity, currTransform.GetPointer());
  currTransform->Modified();
  currTransform->Update();

  double pos[3] = {p.x, p.y, p.z};
  currTransform->InternalTransformPoint(pos, pos);
  p.x = pos[0];
  p.y = pos[1];
  p.z = pos[2];
}

//-----------------------------------------------------------------------------
void vtkSlam::ResetDistanceParameters()
{
  this->Xvalues.clear();
  this->Xvalues.resize(0);
  this->Avalues.clear();
  this->Avalues.resize(0);
  this->Pvalues.clear();
  this->Pvalues.resize(0);
  this->TimeValues.clear();
  this->TimeValues.resize(0);
  this->OutlierDistScale.clear();
  this->OutlierDistScale.resize(0);
  this->RadiusIncertitude.clear();
  this->RadiusIncertitude.resize(0);
}

//-----------------------------------------------------------------------------
void vtkSlam::UpdateTworldUsingTrelative()
{
  // Rotation and translation relative
  Eigen::Matrix<double, 3, 3> Rr, Rw;
  Eigen::Matrix<double, 3, 1> Tr, Tw;
  Rr = GetRotationMatrix(this->Trelative);
  Tr << this->Trelative(3), this->Trelative(4), this->Trelative(5);

  // full rotation
  Rw = GetRotationMatrix(this->Tworld);
  Tw << this->Tworld(3), this->Tworld(4), this->Tworld(5);

  Eigen::Matrix<double, 3, 1> newTw;
  Eigen::Matrix<double, 3, 3> newRw;

  // The new pos of the sensor in the world
  // referential is the previous one composed
  // with the relative motion estimated at the
  // odometry step
  newRw = Rw * Rr;
  newTw = Rw * Tr + Tw;

  double rx = std::atan2(newRw(2, 1), newRw(2, 2));
  double ry = -std::asin(newRw(2, 0));
  double rz = std::atan2(newRw(1, 0), newRw(0, 0));

  // Next estimation of Tworld using
  // the odometry result. This estimation
  // will be used to undistorded the frame
  // if required and to initialize the
  this->Tworld(0) = rx;
  this->Tworld(1) = ry;
  this->Tworld(2) = rz;
  this->Tworld(3) = newTw(0);
  this->Tworld(4) = newTw(1);
  this->Tworld(5) = newTw(2);
}

//-----------------------------------------------------------------------------
/*const*/ unsigned int vtkSlam::Get_RollingGrid_VoxelSize() const
{
  return this->EdgesPointsLocalMap->Get_VoxelSize();
}

//-----------------------------------------------------------------------------
void vtkSlam::Set_RollingGrid_VoxelSize(const unsigned int size)
{
  this->EdgesPointsLocalMap->Set_VoxelSize(size);
  this->PlanarPointsLocalMap->Set_VoxelSize(size);
}

//-----------------------------------------------------------------------------
void vtkSlam::Get_RollingGrid_Grid_NbVoxel(double nbVoxel[3]) const
{
  this->EdgesPointsLocalMap->Get_Grid_NbVoxel(nbVoxel);
}

//-----------------------------------------------------------------------------
void vtkSlam::Set_RollingGrid_Grid_NbVoxel(const double nbVoxel[3])
{
  this->EdgesPointsLocalMap->Set_Grid_NbVoxel(nbVoxel);
  this->PlanarPointsLocalMap->Set_Grid_NbVoxel(nbVoxel);
}

//-----------------------------------------------------------------------------
void vtkSlam::Get_RollingGrid_PointCloud_NbVoxel(double nbVoxel[3]) const
{
  this->EdgesPointsLocalMap->Get_PointCloud_NbVoxel(nbVoxel);
}

//-----------------------------------------------------------------------------
void vtkSlam::Set_RollingGrid_PointCloud_NbVoxel(const double nbVoxel[3])
{
  this->EdgesPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);
  this->PlanarPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);
  this->BlobsPointsLocalMap->Set_PointCloud_NbVoxel(nbVoxel);
}

//-----------------------------------------------------------------------------
/*const*/ double vtkSlam::Get_RollingGrid_LeafVoxelFilterSize() const
{
  return this->EdgesPointsLocalMap->Get_LeafVoxelFilterSize();
}

//-----------------------------------------------------------------------------
void vtkSlam::Set_RollingGrid_LeafVoxelFilterSize(const double size)
{
  this->EdgesPointsLocalMap->Set_LeafVoxelFilterSize(0.75 * size);
  this->PlanarPointsLocalMap->Set_LeafVoxelFilterSize(size);
  this->BlobsPointsLocalMap->Set_LeafVoxelFilterSize(size);
}

//-----------------------------------------------------------------------------
void vtkSlam::SetMaxVelocityAcceleration(double acc)
{
  this->KalmanEstimator.SetMaxVelocityAcceleration(acc);
}

//-----------------------------------------------------------------------------
void vtkSlam::SetMaxAngleAcceleration(double acc)
{
  this->KalmanEstimator.SetMaxAngleAcceleration(acc);
}

//-----------------------------------------------------------------------------
void vtkSlam::SetExternalSensorMeasures(vtkVelodyneTransformInterpolator* interpolator)
{
  if (this->NbrFrameProcessed > 0)
  {
    vtkGenericWarningMacro("The external sensor measures should be provided"
                           << "Before launching any odometry operation");
  }
  this->ExternalMeasures = interpolator;
}

//-----------------------------------------------------------------------------
void vtkSlam::SetMotionModel(int input)
{
  this->MotionModel = input;
  if (input > 0)
    this->KalmanEstimator.SetMode(input - 1);
}

//-----------------------------------------------------------------------------
void vtkSlam::ExportTransforms(const std::string& filename)
{
  std::ofstream file;
  file.open(filename);

  if (!file.is_open())
  {
    vtkGenericWarningMacro("Can't write the specified file");
  }

  std::vector<std::vector<double> > transforms = this->InternalInterp->GetTransformList();
  std::vector<double> T;

  file.precision(12);

  // check if the slam is georeferenced
  vtkDataArray* const zone = this->Trajectory->GetFieldData()->GetArray("zone");
  vtkDataArray* const easting = this->Trajectory->GetFieldData()->GetArray("easting");
  vtkDataArray* const northing = this->Trajectory->GetFieldData()->GetArray("northing");
  vtkDataArray* const height = this->Trajectory->GetFieldData()->GetArray("height");
  bool isGeoreferenced = false;
  double easting0, northing0, height0;
  int utmZone;
  if (zone && zone->GetNumberOfTuples() &&
      easting && easting->GetNumberOfTuples() &&
      northing && northing->GetNumberOfTuples() &&
      height && height->GetNumberOfTuples())
  {
    isGeoreferenced = true;
    utmZone = static_cast<int>(zone->GetComponent(0, 0));
    easting0 = static_cast<double>(easting->GetComponent(0, 0));
    northing0 = static_cast<double>(northing->GetComponent(0, 0));
    height0 = static_cast<double>(height->GetComponent(0, 0));
  }

  if (!isGeoreferenced)
  {
    file << "Time,Rx(Roll),Ry(Pitch),Rz(Yaw),X,Y,Z" << std::endl;
  }
  else
  {
    file << "Time,Rx(Roll),Ry(Pitch),Rz(Yaw),X,Y,Z,easting,northing,height,utm" << std::endl;
  }
  for (unsigned int k = 0; k < transforms.size(); ++k)
  {
    T = transforms[k];
    file << T[0] << "," << T[1] << "," << T[2] << "," << T[3] << ","
         << T[4] << "," << T[5] << "," << T[6] << ",";
    if (isGeoreferenced)
    {
      file << easting0 << "," << northing0 << "," << height0 << "," << utmZone;
    }
    file << std::endl;
  }

  file.close();
  return;
}

//-----------------------------------------------------------------------------
void vtkSlam::SetUndistortion(bool input)
{
  this->Undistortion = input;

  // Use linear interpolator if undistortion has been chosed
  if (this->Undistortion)
  {
    this->InternalInterp = vtkSmartPointer<vtkVelodyneTransformInterpolator>::New();
    this->InternalInterp->SetInterpolationTypeToLinear();
  }
  else
  {
    this->InternalInterp = vtkSmartPointer<vtkVelodyneTransformInterpolator>::New();
    this->InternalInterp->SetInterpolationTypeToNearestLowBounded();
  }
}

//-----------------------------------------------------------------------------
KalmanFilter::KalmanFilter()
{
  this->ResetKalmanFilter();
}

//-----------------------------------------------------------------------------
void KalmanFilter::ResetKalmanFilter()
{
  // set the number of measures observed
  this->NbrMeasures = 6;
  if (this->mode > 0)
  {
    this->NbrMeasures = 7;
  }

  // Fill motion Model diagonal
  this->MotionModel = Eigen::Matrix<double, 12, 12>::Zero();
  for (unsigned int i = 0; i < 12; ++i)
  {
      this->MotionModel(i, i) = 1.0;
  }

  // Fill Estimator covariance
  // Set to zero because without
  // any other information
  this->EstimatorCovariance = Eigen::Matrix<double, 12, 12>::Zero();

  // Fill measure model
  this->MeasureModel = Eigen::MatrixXd(this->NbrMeasures, 12);// ::Matrix<double, 6, 12>::Zero();
  for (unsigned int j = 0; j < 12; ++j)
  {
    for (unsigned int i = 0; i < this->NbrMeasures; ++i)
    {
      this->MeasureModel(i, j) = 0.0;
    }
  }
  for (unsigned int i = 0; i < 6; ++i)
  {
    this->MeasureModel(i, i) = 1.0;
  }

  // Fill Motion model covariance
  this->ModelCovariance = Eigen::Matrix<double, 12, 12>::Zero();

  // Fill vector state
  this->VectorState << 0,0,0,0,0,0,0,0,0,0,0,0;

  // Set the maximale acceleration
  // Settle to 10 m.s-2 (= 1g). it is
  // the maximal acceleration that a "normal"
  // car can endorsed. Moreover, it the acceleration
  // of a falling drone. Seems a good limit
  // Reducing the maximal acceleration will
  // reduce the motion model covariance matrix
  // We can take an additional 20% error
  this->MaxAcceleration = 1.2 * 10.0;

  // Maximal acceleration settled to
  // 1080 degrees / s-2. To have an image
  // the maximale acceleration corresponds
  // to an none-mobile object than can goes
  // up to 3 rotation per secondes (180 per min)
  // in one second. This seems reasonable
  // We can take an additional 20% error
  this->MaxAngleAcceleration = 1.2 * 1080.0 / 180.0 * vtkMath::Pi();
}

//-----------------------------------------------------------------------------
void KalmanFilter::SetInitialStatevector(Eigen::Matrix<double, 12, 1> iniVector, Eigen::Matrix<double, 12, 12> iniCov)
{
  this->VectorState = iniVector;
  this->EstimatorCovariance = iniCov;
}

//-----------------------------------------------------------------------------
void KalmanFilter::SetCurrentTime(double time)
{
  // Update time
  this->PreviousTime = this->CurrentTime;
  this->CurrentTime = time;
  this->DeltaTime = this->CurrentTime - this->PreviousTime;

  // Update motion model matrix
  for (unsigned int i = 0; i <= 5; ++i)
  {
    this->MotionModel(i, i + 6) = this->DeltaTime;
  }

  // Update Motion model covariance matrix
  // angle
  for (unsigned int i = 0; i < 3; ++i)
  {
    this->ModelCovariance(i, i) = std::pow(0.5 * this->MaxAngleAcceleration * std::pow(this->DeltaTime, 2), 2);
  }
  // Position
  for (unsigned int i = 3; i < 6; ++i)
  {
    this->ModelCovariance(i, i) = std::pow(0.5 * this->MaxAcceleration * std::pow(this->DeltaTime, 2), 2);
  }
  // Angle speed
  for (unsigned int i = 6; i < 9; ++i)
  {
    this->ModelCovariance(i, i) = std::pow(this->MaxAngleAcceleration * this->DeltaTime, 2);
  }
  // Velocity
  for (unsigned int i = 9; i < 12; ++i)
  {
    this->ModelCovariance(i, i) = std::pow(this->MaxAcceleration * this->DeltaTime, 2);
  }
}

//-----------------------------------------------------------------------------
void KalmanFilter::SetMeasureCovariance(Eigen::MatrixXd argCov)
{
  this->MeasureCovariance = argCov;
}

//-----------------------------------------------------------------------------
void KalmanFilter::Prediction()
{
  // Prediction using motion model and motion covariance
  // Vector state prediction
  this->VectorStatePredicted = this->MotionModel * this->VectorState;
  // Estimator covariance update
  this->EstimatorCovariance = this->MotionModel * this->EstimatorCovariance * this->MotionModel.transpose() + this->ModelCovariance;
}

//-----------------------------------------------------------------------------
void KalmanFilter::Correction(Eigen::MatrixXd Measure)
{
  // Update the measure model, since we have a non
  // linear link between the state vector and the measure
  // (norm of the velocity) we need to compute the jacobian
  // of the measure function at the current point in the
  // state vector space
  double normV = std::sqrt(std::pow(this->VectorStatePredicted(9), 2) + std::pow(this->VectorStatePredicted(10), 2) + std::pow(this->VectorStatePredicted(11), 2));
  if (this->mode > 0)
  {
    // check that the norm is not null
    double nv = normV;
    if (nv < 1e-6)
      nv = 1.0;

    this->MeasureModel(6, 9) = this->VectorStatePredicted(9) / nv;
    this->MeasureModel(6, 10) = this->VectorStatePredicted(10) / nv;
    this->MeasureModel(6, 11) = this->VectorStatePredicted(11) / nv;
    std::cout << "Vector State: " << std::endl << this->VectorStatePredicted.transpose() << std::endl;
    std::cout << "Measure: " << std::endl << Measure.transpose() << std::endl;
    std::cout << "Measure model: " << std::endl << this->MeasureModel << std::endl;
  }

  // Update using the measure and its covariance
  Eigen::MatrixXd novelty = (this->MeasureModel * this->EstimatorCovariance * this->MeasureModel.transpose() + this->MeasureCovariance);
  Eigen::MatrixXd gain = this->EstimatorCovariance * this->MeasureModel.transpose() * novelty.inverse();

  // Update the vector state estimation
  Eigen::MatrixXd errVector(this->NbrMeasures, 1);
  if (this->mode > 0)
  {
    for (unsigned int k = 0; k < 6; ++k)
    {
      errVector(k) = this->VectorStatePredicted(k);
    }
    errVector(6) = normV;
    errVector = Measure - errVector;
  }
  else
  {
    errVector = Measure - this->MeasureModel * this->VectorStatePredicted;
  }

  this->VectorState = this->VectorStatePredicted + gain * errVector;

  // Update Estimator covariance
  this->EstimatorCovariance = this->EstimatorCovariance - gain * this->MeasureModel * this->EstimatorCovariance;
}

//-----------------------------------------------------------------------------
Eigen::Matrix<double, 12, 1> KalmanFilter::GetStateVector()
{
  return this->VectorState;
}

//-----------------------------------------------------------------------------
void KalmanFilter::SetMaxAngleAcceleration(double acc)
{
  this->MaxAngleAcceleration = acc / 180.0 * vtkMath::Pi();
}

//-----------------------------------------------------------------------------
void KalmanFilter::SetMaxVelocityAcceleration(double acc)
{
  this->MaxAcceleration = acc;
}

//-----------------------------------------------------------------------------
void KalmanFilter::SetMode(int argMode)
{
  this->mode = argMode;
  this->ResetKalmanFilter();
}

//-----------------------------------------------------------------------------
int KalmanFilter::GetMode()
{
  return this->mode;
}

//-----------------------------------------------------------------------------
int KalmanFilter::GetNbrMeasure()
{
  return this->NbrMeasures;
}